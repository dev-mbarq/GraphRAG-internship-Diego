{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Import relevant dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.4 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3362, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3607, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3667, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_35572\\1872036481.py\", line 7, in <module>\n",
      "    from torch_geometric.loader import NeighborLoader\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\torch_geometric\\__init__.py\", line 21, in <module>\n",
      "    import torch_geometric.datasets\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\torch_geometric\\datasets\\__init__.py\", line 18, in <module>\n",
      "    from .qm9 import QM9\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\torch_geometric\\datasets\\qm9.py\", line 22, in <module>\n",
      "    conversion = torch.tensor([\n",
      "c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\torch_geometric\\datasets\\qm9.py:22: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  conversion = torch.tensor([\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.utils import to_undirected\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "\n",
    "try:\n",
    "    # This will work in scripts where __file__ is defined\n",
    "    current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    # Assuming \"src\" is parallel to the script folder\n",
    "    project_root = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "except NameError:\n",
    "    # In notebooks __file__ is not defined: assume we're in notebooks/\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "src_path = os.path.join(project_root, \"src\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "from graph_formatting_utils import prepare_graph_for_gnn\n",
    "from loss_functions import unsupervised_loss\n",
    "from node_embedding_models import GraphSAGE\n",
    "from training_utils import train_in_cpu #, train_in_gpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Check CUDA status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: False\n",
      "GPU Name: No GPU detected\n",
      "CUDA Device Count: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n",
    "print(\"CUDA Device Count:\", torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Load config data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_params': {'channels': [1024, 512, 256], 'num_layers': 2}, 'loader_params': {'num_neighbors': [25, 15], 'batch_size': 512, 'shuffle': True}, 'input_data': {'graph_file_name': 'multihop_graph_w_sem_embeddings.pkl', 'embedding_dim': 1024}, 'optimizer_params': {'learning_rate': 0.0001}, 'training_params': {'num_epochs': 100}}\n"
     ]
    }
   ],
   "source": [
    "# Load GraphSAGE config file\n",
    "config_file_path = os.path.join(\n",
    "    project_root, \"config\", \"graphsage_config.yaml\"\n",
    "    )\n",
    "\n",
    "with open(config_file_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "print(config)\n",
    "\n",
    "input_graph_file_name = config['input_data']['graph_file_name']\n",
    "\n",
    "graphsage_channels = config['model_params']['channels']\n",
    "\n",
    "loader_num_neighbors = config['loader_params']['num_neighbors']\n",
    "loader_batch_size = config['loader_params']['batch_size']\n",
    "loader_shuffle = config['loader_params']['shuffle']\n",
    "\n",
    "training_num_epochs = config['training_params']['num_epochs']\n",
    "optimizer_learning_rate = config['optimizer_params']['learning_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. Embedding model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and format graph\n",
    "graph_path = os.path.join(project_root, \"data\", input_graph_file_name)\n",
    "with open(graph_path, \"rb\") as f:\n",
    "    G = pickle.load(f)\n",
    "\n",
    "formatted_G, incidences = prepare_graph_for_gnn(G, embedding_dim=1024)\n",
    "\n",
    "# Convert the NetworkX graph to a PyTorch Geometric Data object\n",
    "data = from_networkx(formatted_G)\n",
    "\n",
    "# Ensure the graph is undirected\n",
    "data.edge_index = to_undirected(data.edge_index)\n",
    "\n",
    "# Create data attribute \"x\" containing the embeddings of each node complying with the PyTorch Geometric API\n",
    "data.x = data.embedding\n",
    "del data.embedding\n",
    "\n",
    "# Instantiate the GraphSAGE model\n",
    "model = GraphSAGE(\n",
    "    channels=graphsage_channels\n",
    ")\n",
    "\n",
    "# Set device for model training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to the device\n",
    "model = model.to(device)\n",
    "\n",
    "# Instantiate the NeighborLoader for mini-batch training\n",
    "train_loader = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=loader_num_neighbors,  #  neighbors for the first layer, 15 for the second\n",
    "    batch_size=loader_batch_size,  # Batch size\n",
    "    shuffle=loader_shuffle\n",
    ")\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=optimizer_learning_rate)\n",
    "\n",
    "# Define scaler if GPU is available\n",
    "scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    train_in_cpu(model, train_loader, optimizer, num_epochs=training_num_epochs, loss_fn=unsupervised_loss, debug=True)\n",
    "\n",
    "elif torch.cuda.is_available():\n",
    "    pass # Not yet implemented\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F. Save embeddings and embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings as .npy file\n",
    "\n",
    "## 1) Get the device from any parameter in the model\n",
    "#device = next(model.parameters()).device\n",
    "#\n",
    "## 2) Now move your data.x and data.edge_index to that device:\n",
    "#data_x = data.x.to(device)\n",
    "#data_edge_index = data.edge_index.to(device)\n",
    "#\n",
    "## 3) Forward pass with torch.no_grad():\n",
    "#with torch.no_grad():\n",
    "#    embeddings = model(data_x, data_edge_index)\n",
    "#\n",
    "#embeddings_np = embeddings.cpu().numpy()\n",
    "#np.save(\"../data/graphsage_embeddings.npy\", embeddings_np)\n",
    "#print(\"Embeddings saved to graphsage_embeddings.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add Graph_SAGE embeddings to the baseline graph\n",
    "#\n",
    "## 1) Move data to the same device as the model\n",
    "#device = next(model.parameters()).device\n",
    "#data_x = data.x.to(device)\n",
    "#data_edge_index = data.edge_index.to(device)\n",
    "#\n",
    "## 2) Obtain final embeddings from the trained model\n",
    "#with torch.no_grad():\n",
    "#    final_emb = model(data_x, data_edge_index)  # shape [num_nodes, embedding_dim]\n",
    "#    final_emb_np = final_emb.cpu().numpy()\n",
    "#\n",
    "## 3) Add them back to the cleaned_G graph\n",
    "#list_of_nodes = list(G.nodes())  # Must match the node ordering in data\n",
    "#for i, node in enumerate(list_of_nodes):\n",
    "#    # Store as a NumPy array (or you could store as a list if you prefer)\n",
    "#    G.nodes[node][\"SAGE_embedding\"] = final_emb_np[i]\n",
    "#\n",
    "#print(\"SAGE embeddings added to G under 'SAGE_embedding' attribute.\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(f\"../data/multihop_graph_w_sage{num_epochs}_embeddings_1hop.pkl\", \"wb\") as f:\n",
    "#    pickle.dump(G, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save the model's state_dict to disk\n",
    "#torch.save(model.state_dict(), f\"../data/graphsage_{num_epochs}_model_1hop.pth\")\n",
    "#print(\"Model saved to graphsage_model.pth\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def get_new_node_embedding(model, new_feature, device, self_loop=True):\n",
    "#    \"\"\"\n",
    "#    Generate an embedding for a new node using the trained GraphSAGE model.\n",
    "#    \n",
    "#    Parameters:\n",
    "#      model (torch.nn.Module): The trained GraphSAGE model.\n",
    "#      new_feature (torch.Tensor): The new node's initial features of shape (1024,).\n",
    "#      device (torch.device): The device (e.g., cuda) on which the model is located.\n",
    "#      self_loop (bool, default=True): If True, adds a self-loop edge (node connected to itself).\n",
    "#                                      This simulates neighbor aggregation when no neighbors exist.\n",
    "#    \n",
    "#    Returns:\n",
    "#      torch.Tensor: The new node's embedding of shape (out_channels,).\n",
    "#    \"\"\"\n",
    "#    # Set the model to evaluation mode.\n",
    "#    model.eval()\n",
    "#    \n",
    "#    # Move the new node's features to the correct device.\n",
    "#    new_feature = new_feature.to(device)\n",
    "#    \n",
    "#    if self_loop:\n",
    "#        # Create a self-loop edge_index. This indicates that the node is connected to itself.\n",
    "#        # The edge_index tensor must have shape [2, num_edges]; here we create a single edge (0,0).\n",
    "#        edge_index = torch.tensor([[0], [0]], dtype=torch.long, device=device)\n",
    "#    else:\n",
    "#        # Alternatively, if you prefer no edges, you can pass an empty edge_index.\n",
    "#        # Note: Without a self-loop, the model may not transform the features as intended.\n",
    "#        edge_index = torch.empty((2, 0), dtype=torch.long, device=device)\n",
    "#    \n",
    "#    # GraphSAGE expects a batch dimension, so unsqueeze new_feature to shape [1, 1024].\n",
    "#    with torch.no_grad():\n",
    "#        new_embedding = model(new_feature.unsqueeze(0), edge_index)\n",
    "#    \n",
    "#    # Remove the batch dimension to return a tensor of shape [out_channels].\n",
    "#    return new_embedding.squeeze(0)\n",
    "#\n",
    "## Example usage:\n",
    "## Assuming 'model' is your trained GraphSAGE and you have a new node feature vector of size 1024.\n",
    "#new_feature = torch.randn(1024)  # Replace with the actual feature vector for the new node.\n",
    "#device = next(model.parameters()).device  # Get the device from the model.\n",
    "#new_node_embedding = get_new_node_embedding(model, new_feature, device, self_loop=True)\n",
    "#print(\"New node embedding shape:\", new_node_embedding.shape)\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311_graphsage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
