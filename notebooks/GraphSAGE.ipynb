{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import random\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import NeighborLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=2):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        \n",
    "        # First GraphSAGE layer: input (embeddings) â†’ hidden layer\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        \n",
    "        # Intermediate layers (if num_layers > 2)\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "        \n",
    "        # Last GraphSAGE layer: hidden layer â†’ final embedding\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for conv in self.convs[:-1]:  # Intermediate layers\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)  # ReLU activation\n",
    "        x = self.convs[-1](x, edge_index)  # Last layer (no activation)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphSAGE(\n",
    "    in_channels=1024,   # Input features (BGE-M3 embeddings)\n",
    "    hidden_channels=512,  # First hidden layer (alto para mÃ¡xima capacidad)\n",
    "    out_channels=256,   # Output embeddings (mÃ¡s ricos)\n",
    "    num_layers=2        # Mantenemos 2 capas (2 hops)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=[25, 15],  # MÃ¡s vecinos en cada hop (sin desbordar memoria)\n",
    "    batch_size=512,  # Balanceamos tamaÃ±o grande sin sobrecargar GPU\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "data = data.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsupervised_loss(z, edge_index, num_neg_samples=5):\n",
    "    \"\"\"\n",
    "    Compute GraphSAGE unsupervised loss with negative sampling.\n",
    "\n",
    "    Parameters:\n",
    "        z (Tensor): Node embeddings of shape [num_nodes, embedding_dim].\n",
    "        edge_index (Tensor): Graph connectivity of shape [2, num_edges].\n",
    "        num_neg_samples (int): Number of negative samples per node.\n",
    "\n",
    "    Returns:\n",
    "        loss (Tensor): Computed contrastive loss.\n",
    "    \"\"\"\n",
    "    pos_loss = 0  # Loss for positive node pairs\n",
    "    neg_loss = 0  # Loss for negative node pairs\n",
    "\n",
    "    num_nodes = z.shape[0]  # Number of nodes in the graph\n",
    "\n",
    "    for edge in edge_index.T:  # Iterate over each edge in the graph\n",
    "        u, v = edge  # Extract source node (u) and destination node (v)\n",
    "\n",
    "        # Positive pair loss (nodes that are neighbors)\n",
    "        pos_loss += torch.log(torch.sigmoid(torch.dot(z[u], z[v])))\n",
    "\n",
    "        # Negative sampling (random nodes that are NOT neighbors)\n",
    "        for _ in range(num_neg_samples):\n",
    "            v_neg = random.randint(0, num_nodes - 1)\n",
    "            while v_neg in edge_index[1]:  # Ensure v_neg is NOT a neighbor\n",
    "                v_neg = random.randint(0, num_nodes - 1)\n",
    "\n",
    "            neg_loss += torch.log(1 - torch.sigmoid(torch.dot(z[u], z[v_neg])))\n",
    "\n",
    "    loss = -(pos_loss + neg_loss) / edge_index.shape[1]  # Normalize by number of edges\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)  # Mover batch a GPU\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.cuda.amp.autocast():  # Precision mixta (velocidad extra)\n",
    "            z = model(batch.x, batch.edge_index)\n",
    "            loss = unsupervised_loss(z, batch.edge_index)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "for epoch in range(100):  # Â¡Duro con 100 Ã©pocas!\n",
    "    train()\n",
    "    print(f\"ðŸ”¥ Epoch {epoch} completada. ðŸ”¥\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
