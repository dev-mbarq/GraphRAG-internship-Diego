{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import SAGEConv\n",
    "import random\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.utils import to_undirected\n",
    "import networkx as nx\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: True\n",
      "GPU Name: NVIDIA L40S\n",
      "CUDA Device Count: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n",
    "print(\"CUDA Device Count:\", torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar el grafo\n",
    "with open(\"../data/graph_w_embeddings_full_prototype.pkl\", \"rb\") as f:\n",
    "    G = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_graph_for_graphsage(G, embedding_dim=1024, remove_incomplete=True):\n",
    "    \"\"\"\n",
    "    Cleans a NetworkX graph for GraphSAGE training by:\n",
    "      1. Converting the graph to an undirected version.\n",
    "      2. Removing all edge attributes.\n",
    "      3. Ensuring each node has a valid \"embedding\" attribute:\n",
    "         - If an embedding is missing:\n",
    "             - If remove_incomplete is True: remove the node.\n",
    "             - Otherwise, print a warning and assign a default zero embedding.\n",
    "         - If the embedding is stored as a dictionary (with key \"embedding\"),\n",
    "           extract the value.\n",
    "         - If the embedding is a list or numpy.ndarray, convert it to a torch.Tensor.\n",
    "      4. Removing all other node attributes (keeping only \"embedding\").\n",
    "\n",
    "    Parameters:\n",
    "      G (networkx.Graph): The input graph.\n",
    "      embedding_dim (int): Expected dimension of each node's embedding.\n",
    "      remove_incomplete (bool): If True, remove nodes without an embedding;\n",
    "                                if False, assign a default zero tensor.\n",
    "\n",
    "    Returns:\n",
    "      networkx.Graph: The cleaned, undirected graph.\n",
    "    \"\"\"\n",
    "    # 1. Convert to undirected graph\n",
    "    G_undirected = nx.Graph(nx.to_undirected(G))\n",
    "    \n",
    "    # 2. Clean node attributes\n",
    "    # Use list(G_undirected.nodes()) since we may remove nodes\n",
    "    for node in list(G_undirected.nodes()):\n",
    "        node_attrs = G_undirected.nodes[node]\n",
    "        embedding = node_attrs.get(\"embedding\", None)\n",
    "        \n",
    "        if embedding is None:\n",
    "            # Node is missing embedding\n",
    "            if remove_incomplete:\n",
    "                print(f\"[INFO] Removing node {node} because it has no 'embedding'.\")\n",
    "                G_undirected.remove_node(node)\n",
    "                continue  # Skip further processing for this node\n",
    "            else:\n",
    "                print(f\"[WARNING] Node {node} has no 'embedding'. Assigning default zero embedding.\")\n",
    "                embedding = np.zeros(embedding_dim, dtype=np.float32)\n",
    "        \n",
    "        # If embedding is a dictionary with a key \"embedding\", extract it.\n",
    "        if isinstance(embedding, dict) and \"embedding\" in embedding:\n",
    "            embedding = embedding[\"embedding\"]\n",
    "        \n",
    "        # Convert list or numpy.ndarray to a numpy array of type float32\n",
    "        if isinstance(embedding, list):\n",
    "            embedding = np.array(embedding, dtype=np.float32)\n",
    "        elif isinstance(embedding, np.ndarray):\n",
    "            embedding = embedding.astype(np.float32)\n",
    "        \n",
    "        # Now convert to a torch tensor if it's not already\n",
    "        if not isinstance(embedding, torch.Tensor):\n",
    "            embedding = torch.tensor(embedding, dtype=torch.float32)\n",
    "        \n",
    "        # Check if the embedding has the expected shape\n",
    "        if embedding.dim() != 1 or embedding.shape[0] != embedding_dim:\n",
    "            print(f\"[WARNING] Node {node} embedding shape is {embedding.shape}, expected ({embedding_dim},).\")\n",
    "        \n",
    "        # Reassign the cleaned embedding back to the node\n",
    "        node_attrs[\"embedding\"] = embedding\n",
    "        \n",
    "        # Remove any other attributes besides 'embedding'\n",
    "        keys_to_remove = [k for k in node_attrs.keys() if k != \"embedding\"]\n",
    "        for k in keys_to_remove:\n",
    "            del node_attrs[k]\n",
    "\n",
    "    #Remove all edge attributes\n",
    "    for u, v in G_undirected.edges():\n",
    "        for key in list(G_undirected[u][v].keys()):\n",
    "            del G_undirected[u][v][key] \n",
    "    \n",
    "    return G_undirected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Removing node Yardbarker because it has no 'embedding'.\n",
      "[INFO] Removing node Engadget because it has no 'embedding'.\n"
     ]
    }
   ],
   "source": [
    "cleaned_G = clean_graph_for_graphsage(G, embedding_dim=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in cleaned_G.nodes():\n",
    "    emb = cleaned_G.nodes[node][\"embedding\"]\n",
    "    if emb is None:\n",
    "        print(f\"[ERROR] Node {node} is still missing embedding!\")\n",
    "    elif not isinstance(emb, torch.Tensor):\n",
    "        print(f\"[ERROR] Node {node} embedding is not a torch.Tensor!\")\n",
    "    elif emb.shape != (1024,):\n",
    "        print(f\"[ERROR] Node {node} has shape {emb.shape} != ({1024},)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir el grafo de NetworkX a PyTorch Geometric Data\n",
    "data = from_networkx(cleaned_G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.edge_index = to_undirected(data.edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.x = data.embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphSAGE(torch.nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, num_layers=2):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        \n",
    "        # First GraphSAGE layer: input (embeddings) → hidden layer\n",
    "        self.convs.append(SAGEConv(in_channels, hidden_channels))\n",
    "        \n",
    "        # Intermediate layers (if num_layers > 2)\n",
    "        for _ in range(num_layers - 2):\n",
    "            self.convs.append(SAGEConv(hidden_channels, hidden_channels))\n",
    "        \n",
    "        # Last GraphSAGE layer: hidden layer → final embedding\n",
    "        self.convs.append(SAGEConv(hidden_channels, out_channels))\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        for conv in self.convs[:-1]:  # Intermediate layers\n",
    "            x = conv(x, edge_index)\n",
    "            x = F.relu(x)  # ReLU activation\n",
    "        x = self.convs[-1](x, edge_index)  # Last layer (no activation)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphSAGE(\n",
    "    in_channels=1024,   # Input features (BGE-M3 embeddings)\n",
    "    hidden_channels=512,  # First hidden layer (alto para máxima capacidad)\n",
    "    out_channels=256,   # Output embeddings (más ricos)\n",
    "    num_layers=2        # Mantenemos 2 capas (2 hops)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diomedea/.pyenv/versions/3.11.6/envs/graphsage/lib/python3.11/site-packages/torch_geometric/sampler/neighbor_sampler.py:61: UserWarning: Using 'NeighborSampler' without a 'pyg-lib' installation is deprecated and will be removed soon. Please install 'pyg-lib' for accelerated neighborhood sampling\n",
      "  warnings.warn(f\"Using '{self.__class__.__name__}' without a \"\n"
     ]
    }
   ],
   "source": [
    "train_loader = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=[25, 15],  # Más vecinos en cada hop (sin desbordar memoria)\n",
    "    batch_size=512,  # Balanceamos tamaño grande sin sobrecargar GPU\n",
    "    shuffle=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo en: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Para el modelo:\n",
    "print(\"Modelo en:\", next(model.parameters()).device)\n",
    "\n",
    "# Para los datos (ejemplo con data.x):#\n",
    "#print(\"Data en:\", data.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unsupervised_loss(z, edge_index, num_neg_samples=5):\n",
    "    \"\"\"\n",
    "    Compute GraphSAGE unsupervised loss with negative sampling.\n",
    "\n",
    "    Parameters:\n",
    "        z (Tensor): Node embeddings of shape [num_nodes, embedding_dim].\n",
    "        edge_index (Tensor): Graph connectivity of shape [2, num_edges].\n",
    "        num_neg_samples (int): Number of negative samples per node.\n",
    "\n",
    "    Returns:\n",
    "        loss (Tensor): Computed contrastive loss.\n",
    "    \"\"\"\n",
    "    pos_loss = torch.tensor(0.0, device=z.device)  # Loss for positive node pairs\n",
    "    neg_loss = torch.tensor(0.0, device=z.device)  # Loss for negative node pairs\n",
    "\n",
    "    num_nodes = z.shape[0]  # Number of nodes in the graph\n",
    "\n",
    "    for edge in edge_index.T:  # Iterate over each edge in the graph\n",
    "        u, v = edge  # Extract source node (u) and destination node (v)\n",
    "\n",
    "        # Positive pair loss (nodes that are neighbors)\n",
    "        pos_loss += torch.log(torch.sigmoid(torch.dot(z[u], z[v])))\n",
    "\n",
    "        # Negative sampling (random nodes that are NOT neighbors)\n",
    "        for _ in range(num_neg_samples):\n",
    "            v_neg = random.randint(0, num_nodes - 1)\n",
    "            while v_neg in edge_index[1]:  # Ensure v_neg is NOT a neighbor\n",
    "                v_neg = random.randint(0, num_nodes - 1)\n",
    "\n",
    "            neg_loss += torch.log(1 - torch.sigmoid(torch.dot(z[u], z[v_neg])))\n",
    "\n",
    "    loss = -(pos_loss + neg_loss) / edge_index.shape[1]  # Normalize by number of edges\n",
    "    return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(edge_index=[2, 9002], embedding=[2620, 1024], num_nodes=2620, x=[2620, 1024])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔥 Epoch 0 completada. 🔥\n",
      "🔥 Epoch 1 completada. 🔥\n",
      "🔥 Epoch 2 completada. 🔥\n",
      "🔥 Epoch 3 completada. 🔥\n",
      "🔥 Epoch 4 completada. 🔥\n"
     ]
    }
   ],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)  # Mover batch a GPU\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        with torch.amp.autocast('cuda'):  # Precision mixta (velocidad extra)\n",
    "            z = model(batch.x, batch.edge_index)\n",
    "            loss = unsupervised_loss(z, batch.edge_index)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "for epoch in range(100):  # ¡Duro con 100 épocas!\n",
    "    train()\n",
    "    print(f\"🔥 Epoch {epoch} completada. 🔥\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphsage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
