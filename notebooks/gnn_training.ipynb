{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.2.4 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3098, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3153, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3362, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3607, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3667, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Usuario\\AppData\\Local\\Temp\\ipykernel_10928\\2681109064.py\", line 10, in <module>\n",
      "    from torch_geometric.data import Data\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\torch_geometric\\__init__.py\", line 21, in <module>\n",
      "    import torch_geometric.datasets\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\torch_geometric\\datasets\\__init__.py\", line 18, in <module>\n",
      "    from .qm9 import QM9\n",
      "  File \"c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\torch_geometric\\datasets\\qm9.py\", line 22, in <module>\n",
      "    conversion = torch.tensor([\n",
      "c:\\Users\\Usuario\\pyenvs\\python311_graphsage\\Lib\\site-packages\\torch_geometric\\datasets\\qm9.py:22: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  conversion = torch.tensor([\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch_geometric.utils import to_undirected\n",
    "from torch_geometric.utils.convert import from_networkx\n",
    "\n",
    "# Add \"src\" path to Python path\n",
    "sys.path.append(os.path.abspath(\"../src\"))\n",
    "\n",
    "# Import custom graph formatting function\n",
    "from graph_formatting_utils import format_graph_for_graphsage\n",
    "from models import GraphSAGE\n",
    "from losses import unsupervised_loss\n",
    "from train import train_in_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA Available: False\n",
      "GPU Name: No GPU detected\n",
      "CUDA Device Count: 0\n"
     ]
    }
   ],
   "source": [
    "# Check CUDA status\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"GPU Name:\", torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"No GPU detected\")\n",
    "print(\"CUDA Device Count:\", torch.cuda.device_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This should be removed from this notebook\n",
    "with open(\"../data/multihop_graph_w_sem_embeddings.pkl\", \"rb\") as f:\n",
    "    G = pickle.load(f)\n",
    "\n",
    "cleaned_G = format_graph_for_graphsage(G, embedding_dim=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the NetworkX graph to a PyTorch Geometric Data object\n",
    "data = from_networkx(cleaned_G)\n",
    "\n",
    "# Ensure the graph is undirected\n",
    "data.edge_index = to_undirected(data.edge_index)\n",
    "\n",
    "# Create data attribute \"x\" containing the embeddings of each node complying with the PyTorch Geometric API\n",
    "data.x = data.embedding\n",
    "\n",
    "# Instantiate the GraphSAGE model\n",
    "model = GraphSAGE(\n",
    "    in_channels=1024,   # Input features (BGE-M3 embeddings)\n",
    "    hidden_channels=512,  # First hidden layer (alto para máxima capacidad)\n",
    "    out_channels=256,   # Output embeddings (más ricos)\n",
    "    num_layers=2        # Mantenemos 2 capas (2 hops)\n",
    ")\n",
    "\n",
    "# Set device for model training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to the device\n",
    "model = model.to(device)\n",
    "\n",
    "# Instantiate the NeighborLoader for mini-batch training\n",
    "train_loader = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=[25, 15],  # 25 neighbors for the first layer, 15 for the second\n",
    "    batch_size=512,  # Batch size\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Define scaler if GPU is available\n",
    "scaler = torch.cuda.amp.GradScaler() if torch.cuda.is_available() else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    train_in_cpu(model, train_loader, optimizer, num_epochs=5, loss_fn=unsupervised_loss, debug=True)\n",
    "\n",
    "elif torch.cuda.is_available():\n",
    "    pass # Not yet implemented\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Batch shapes - batch.x: torch.Size([2773, 1024]), batch.edge_index: torch.Size([2, 8382])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2773, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[-0.0101, -0.4896,  0.1358,  ..., -0.7491,  0.0576,  0.1241],\n",
      "        [ 0.0436, -0.3235, -0.1622,  ..., -0.5725, -0.0701, -0.1153],\n",
      "        [ 0.1624, -0.2986, -0.0804,  ..., -0.6393, -0.1481, -0.5903],\n",
      "        [ 0.3485, -0.3122, -0.0451,  ..., -0.5101,  0.2627, -0.1359],\n",
      "        [ 0.2253,  0.0853, -0.2239,  ..., -0.7649,  0.4128, -0.1385]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 25.5706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 25.5706\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2798, 1024]), batch.edge_index: torch.Size([2, 8838])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2798, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.0621, -0.0660, -0.2876,  ..., -0.4607, -0.0407, -0.0907],\n",
      "        [ 0.2154, -0.0383, -0.1937,  ..., -0.6689,  0.2169, -0.5168],\n",
      "        [ 0.0945, -0.0185,  0.0920,  ..., -0.6374,  0.5040, -0.1033],\n",
      "        [ 0.3072, -0.1978,  0.0140,  ..., -0.8093, -0.0475, -0.3139],\n",
      "        [ 0.1989, -0.3348, -0.1228,  ..., -0.2762, -0.0823,  0.1049]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 14.5771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 40.1477\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2829, 1024]), batch.edge_index: torch.Size([2, 9014])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2829, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.4718,  0.0713,  0.0891,  ..., -0.3726, -0.4004, -0.0769],\n",
      "        [ 0.1594,  0.0526, -0.0022,  ..., -0.5512, -0.0227, -0.2478],\n",
      "        [ 0.1313, -0.1231,  0.0910,  ..., -0.4452, -0.0829, -0.0795],\n",
      "        [ 0.1714, -0.0217,  0.1649,  ..., -0.8307, -0.2780, -0.3727],\n",
      "        [ 0.2161, -0.2287,  0.0990,  ..., -0.4482, -0.1093, -0.0223]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 7.8850\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 48.0328\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2854, 1024]), batch.edge_index: torch.Size([2, 8864])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2854, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.5466, -0.0970,  0.1330,  ..., -0.4868, -0.5332, -0.0880],\n",
      "        [ 0.2894, -0.1147,  0.0031,  ..., -0.4096, -0.4167,  0.0618],\n",
      "        [ 0.1758, -0.1613, -0.0102,  ..., -0.5733, -0.3134, -0.1464],\n",
      "        [ 0.3503,  0.0716,  0.0202,  ..., -0.6801, -0.2435, -0.5106],\n",
      "        [-0.1137, -0.1539,  0.0058,  ..., -0.3366, -0.1248, -0.0309]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 4.5439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 52.5766\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2890, 1024]), batch.edge_index: torch.Size([2, 8871])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2890, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.3719, -0.2395,  0.4243,  ..., -0.4526, -0.5999, -0.0178],\n",
      "        [ 0.4648,  0.1823,  0.1841,  ..., -0.4102, -0.5580, -0.0431],\n",
      "        [ 0.1148,  0.0546,  0.1070,  ..., -0.5404, -0.4084, -0.4012],\n",
      "        [ 0.1310,  0.1657,  0.2092,  ..., -0.7350, -0.4314, -0.2093],\n",
      "        [ 0.2275, -0.0559, -0.0530,  ..., -0.4931, -0.4034, -0.3024]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 3.3183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 55.8949\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2852, 1024]), batch.edge_index: torch.Size([2, 8660])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2852, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.1374, -0.0617,  0.2583,  ..., -0.6804,  0.1509, -0.5688],\n",
      "        [ 0.0921, -0.1647,  0.4435,  ..., -0.6013, -0.6714, -0.0429],\n",
      "        [-0.1905, -0.2266,  0.4538,  ..., -0.4621, -0.4210,  0.2639],\n",
      "        [ 0.1401,  0.3312,  0.1466,  ..., -0.2685, -0.5533, -0.4255],\n",
      "        [ 0.2251, -0.0286,  0.0260,  ..., -0.3888, -0.3370, -0.1145]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 2.9067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 58.8016\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2406, 1024]), batch.edge_index: torch.Size([2, 6183])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2406, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.0459, -0.0556,  0.2159,  ..., -0.5213,  0.0624, -0.2174],\n",
      "        [ 0.2345, -0.0442,  0.1402,  ..., -0.2845, -0.3533, -0.1663],\n",
      "        [ 0.3217, -0.1812,  0.2958,  ..., -0.4938, -0.2418, -0.0506],\n",
      "        [ 0.0911,  0.1471,  0.2066,  ..., -0.1141, -0.6457,  0.1680],\n",
      "        [-0.0434,  0.0999,  0.2399,  ..., -0.5188, -0.1741, -0.1716]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 3.7911\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  20%|██        | 1/5 [06:39<26:38, 399.60s/it, avg_loss=8.9418, mean_norm=3.4058, std_norm=1.0688]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 62.5927\n",
      "[DEBUG] Number of embeddings collected: 7\n",
      "[DEBUG] Epoch embeddings shape: torch.Size([19402, 256])\n",
      "[DEBUG] Embeddings norms statistics -> min: 0.4390, max: 6.4891, mean: 3.4058, std: 1.0688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Batch shapes - batch.x: torch.Size([2806, 1024]), batch.edge_index: torch.Size([2, 8644])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2806, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.0470,  0.2023,  0.0781,  ..., -0.6321, -0.3384, -0.2242],\n",
      "        [ 0.0562,  0.0536,  0.3626,  ..., -0.2599, -0.3160, -0.0556],\n",
      "        [ 0.2222,  0.2649, -0.1964,  ..., -0.2492, -0.2320, -0.0896],\n",
      "        [ 0.1363, -0.0483,  0.1352,  ..., -0.6678, -0.2166, -0.4793],\n",
      "        [ 0.2180,  0.0561,  0.0741,  ..., -0.4968, -0.1927, -0.4303]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 2.5357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 2.5357\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2806, 1024]), batch.edge_index: torch.Size([2, 8591])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2806, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.1985, -0.0076,  0.1607,  ..., -0.0387, -0.2682,  0.0510],\n",
      "        [-0.0918,  0.1029,  0.5126,  ..., -0.4833, -0.0418,  0.0230],\n",
      "        [ 0.2078,  0.1090,  0.1198,  ..., -0.6740, -0.3909, -0.3028],\n",
      "        [-0.0549,  0.0479,  0.1723,  ..., -0.3135, -0.2090, -0.3726],\n",
      "        [ 0.0584,  0.0595,  0.3689,  ..., -0.2239, -0.5520, -0.0312]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 2.4742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 5.0099\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2845, 1024]), batch.edge_index: torch.Size([2, 8720])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2845, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.2772,  0.1450,  0.5209,  ..., -0.1903, -0.5816,  0.0809],\n",
      "        [ 0.0891,  0.1393,  0.2236,  ..., -0.3898, -0.1523, -0.3916],\n",
      "        [-0.1833,  0.1204,  0.4451,  ..., -0.4590, -0.2104,  0.0066],\n",
      "        [ 0.1333, -0.1049,  0.1234,  ..., -0.0477, -0.3847, -0.0121],\n",
      "        [ 0.2881, -0.0772,  0.5542,  ..., -0.3071, -0.4960, -0.0125]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 2.3597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 7.3696\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2879, 1024]), batch.edge_index: torch.Size([2, 8917])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2879, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.2268,  0.0492,  0.2546,  ..., -0.3265, -0.5711, -0.1367],\n",
      "        [ 0.1798,  0.2035,  0.4192,  ..., -0.2950, -0.4752, -0.1757],\n",
      "        [ 0.2353,  0.1532,  0.2346,  ..., -0.4805, -0.2565, -0.4424],\n",
      "        [ 0.1850, -0.1047,  0.1528,  ..., -0.1120, -0.2240, -0.2068],\n",
      "        [ 0.1903,  0.0449,  0.6091,  ..., -0.1657, -0.0735, -0.6901]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 2.2515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 9.6211\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2748, 1024]), batch.edge_index: torch.Size([2, 8647])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2748, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[-0.0263,  0.2051,  0.1432,  ..., -0.5264, -0.0757, -0.5416],\n",
      "        [ 0.3643,  0.1926,  0.4340,  ..., -0.4697, -0.2573, -0.5157],\n",
      "        [ 0.1040, -0.1549,  0.1190,  ..., -0.3709, -0.6279, -0.2750],\n",
      "        [ 0.1676,  0.2346,  0.1887,  ..., -0.5384, -0.4016, -0.2142],\n",
      "        [ 0.2395,  0.0887,  0.5063,  ..., -0.5507, -0.1983, -0.4372]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 2.2429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 11.8640\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2824, 1024]), batch.edge_index: torch.Size([2, 8565])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2824, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[-0.1220,  0.1716,  0.5887,  ..., -0.2364, -0.4449, -0.3976],\n",
      "        [ 0.1003,  0.2963,  0.1157,  ..., -0.5032, -0.1963, -0.4133],\n",
      "        [ 0.0928,  0.0538,  0.0787,  ..., -0.1653, -0.3859, -0.4108],\n",
      "        [ 0.2056,  0.0204,  0.0605,  ..., -0.1704, -0.4365, -0.3054],\n",
      "        [ 0.1153,  0.1878,  0.1990,  ..., -0.5844, -0.4910, -0.3941]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 2.4104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 14.2744\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2359, 1024]), batch.edge_index: torch.Size([2, 6387])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2359, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.3541,  0.1138,  0.3918,  ..., -0.2143, -0.3387, -0.1860],\n",
      "        [ 0.0600, -0.1749,  0.5074,  ..., -0.2238, -0.6953, -0.1951],\n",
      "        [ 0.2597, -0.1498,  0.6086,  ..., -0.3014, -0.5990, -0.1343],\n",
      "        [ 0.3109,  0.0443,  0.5209,  ..., -0.3601, -0.3076, -0.2531],\n",
      "        [-0.0160, -0.1513,  0.5545,  ..., -0.3378, -0.0336,  0.0291]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 2.9731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  40%|████      | 2/5 [13:09<19:42, 394.04s/it, avg_loss=2.4639, mean_norm=3.6657, std_norm=1.4974]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 17.2474\n",
      "[DEBUG] Number of embeddings collected: 7\n",
      "[DEBUG] Epoch embeddings shape: torch.Size([19267, 256])\n",
      "[DEBUG] Embeddings norms statistics -> min: 0.4373, max: 7.1074, mean: 3.6657, std: 1.4974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Batch shapes - batch.x: torch.Size([2885, 1024]), batch.edge_index: torch.Size([2, 8910])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2885, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.1922,  0.0493,  0.6151,  ..., -0.2620, -0.6148, -0.0654],\n",
      "        [ 0.0585,  0.0452,  0.2979,  ..., -0.3822, -0.4804, -0.0854],\n",
      "        [ 0.1152,  0.0284,  0.3339,  ..., -0.7122, -0.6350, -0.2686],\n",
      "        [ 0.1766, -0.0100,  0.4114,  ..., -0.3708, -0.4349, -0.2257],\n",
      "        [ 0.2152,  0.3070,  0.2967,  ..., -0.0657, -0.5135, -0.4032]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 2.2317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 2.2317\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2766, 1024]), batch.edge_index: torch.Size([2, 8310])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2766, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.2061, -0.1660,  0.4211,  ..., -0.2679, -0.1810, -0.5953],\n",
      "        [ 0.3445,  0.0125,  0.3468,  ..., -0.2850, -0.4822, -0.2517],\n",
      "        [ 0.2063,  0.0667,  0.2685,  ..., -0.5549, -0.4558, -0.5605],\n",
      "        [ 0.0751, -0.0067,  0.0717,  ..., -0.2074, -0.5124, -0.2897],\n",
      "        [ 0.0501,  0.0539, -0.0565,  ..., -0.1868, -0.8410, -0.0753]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 2.3331\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 4.5648\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2786, 1024]), batch.edge_index: torch.Size([2, 8534])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2786, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.2338,  0.1606,  0.4001,  ..., -0.4662, -0.6151, -0.4738],\n",
      "        [ 0.2193,  0.0864,  0.5152,  ..., -0.1697, -0.5510, -0.3216],\n",
      "        [ 0.2114,  0.0993,  0.5347,  ..., -0.4274, -0.5056, -0.4078],\n",
      "        [ 0.4386,  0.0636,  0.5588,  ..., -0.0753, -0.4516, -0.1543],\n",
      "        [ 0.2411,  0.0446,  0.4528,  ..., -0.3935, -0.2746, -0.2295]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 2.1492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 6.7141\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2750, 1024]), batch.edge_index: torch.Size([2, 8348])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2750, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.1617,  0.4305,  0.4720,  ..., -0.2742, -0.4756, -0.2028],\n",
      "        [ 0.3053,  0.0822,  0.6215,  ..., -0.2653, -0.4871, -0.1889],\n",
      "        [ 0.1339,  0.0067,  0.3717,  ..., -0.5554, -0.6573, -0.5196],\n",
      "        [ 0.3784,  0.0445,  0.3911,  ..., -0.4906, -0.6839, -0.2329],\n",
      "        [ 0.3523,  0.0582,  0.3530,  ..., -0.3209, -0.3444, -0.3927]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 2.1726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 8.8867\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2892, 1024]), batch.edge_index: torch.Size([2, 9157])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2892, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.3835,  0.2286,  0.3655,  ..., -0.4844, -0.6460, -0.7159],\n",
      "        [ 0.2711,  0.0919,  0.3687,  ..., -0.5370, -0.0794, -0.6587],\n",
      "        [ 0.2786,  0.0799,  0.3664,  ..., -0.2929, -0.6123, -0.3540],\n",
      "        [ 0.2715,  0.2884,  0.3384,  ..., -0.6011, -0.3424, -0.5151],\n",
      "        [ 0.3214,  0.2963,  0.4704,  ..., -0.4967, -0.4264, -0.3744]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 1.8960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 10.7826\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2852, 1024]), batch.edge_index: torch.Size([2, 8886])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2852, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.1694,  0.1298,  0.4012,  ..., -0.5644, -0.3847, -0.6111],\n",
      "        [ 0.0459, -0.2942,  0.4340,  ..., -0.3680, -0.4757, -0.2629],\n",
      "        [ 0.2078,  0.2097,  0.4605,  ..., -0.4894, -0.7084, -0.7512],\n",
      "        [ 0.2556, -0.0276,  0.3014,  ..., -0.3587, -0.5148, -0.6329],\n",
      "        [ 0.3010, -0.0667,  0.2679,  ..., -0.7648, -0.7865, -0.6452]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 1.8431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 12.6258\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2382, 1024]), batch.edge_index: torch.Size([2, 6133])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2382, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.2537, -0.2252,  0.2051,  ..., -0.4556, -0.7526, -0.4772],\n",
      "        [ 0.3726,  0.0623,  0.3618,  ..., -0.0409, -0.5009, -0.2764],\n",
      "        [ 0.1556, -0.2455,  0.3042,  ..., -0.3108, -0.5647, -0.0567],\n",
      "        [ 0.3227,  0.1791,  0.2187,  ..., -0.5935, -0.6921, -0.3183],\n",
      "        [ 0.1611, -0.0269,  0.3571,  ..., -0.3375, -0.5286, -0.4139]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 2.8144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  60%|██████    | 3/5 [19:34<12:59, 389.98s/it, avg_loss=2.2057, mean_norm=4.2927, std_norm=2.1364]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 15.4401\n",
      "[DEBUG] Number of embeddings collected: 7\n",
      "[DEBUG] Epoch embeddings shape: torch.Size([19313, 256])\n",
      "[DEBUG] Embeddings norms statistics -> min: 0.4367, max: 8.0040, mean: 4.2927, std: 2.1364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Batch shapes - batch.x: torch.Size([2889, 1024]), batch.edge_index: torch.Size([2, 8780])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2889, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.2837, -0.0332,  0.0774,  ..., -0.6588, -0.8168, -0.3877],\n",
      "        [ 0.2594,  0.1550,  0.2262,  ..., -0.3599, -0.3778, -0.3628],\n",
      "        [ 0.1017,  0.1797,  0.5124,  ..., -0.3922, -0.5404, -0.6578],\n",
      "        [ 0.1667, -0.0942,  0.3699,  ..., -0.2805, -0.5095, -0.1990],\n",
      "        [ 0.1517,  0.0402,  0.3128,  ..., -0.1600, -0.3909, -0.5813]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 1.9579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 1.9579\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2800, 1024]), batch.edge_index: torch.Size([2, 8638])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2800, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.5413,  0.0833,  0.3952,  ..., -0.5503, -0.1974, -0.6337],\n",
      "        [ 0.3844,  0.0475,  0.3939,  ..., -0.2546, -0.4917, -0.4577],\n",
      "        [ 0.2234, -0.1316,  0.2326,  ..., -0.3068, -0.6977, -0.3254],\n",
      "        [ 0.4140, -0.0426,  0.2887,  ..., -0.2586, -0.4843, -0.3446],\n",
      "        [ 0.3110,  0.0289,  0.1681,  ..., -0.3870, -0.7904, -0.3347]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 1.8429\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 3.8008\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2784, 1024]), batch.edge_index: torch.Size([2, 8771])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2784, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.3537, -0.0163,  0.3220,  ..., -0.3257, -0.6041, -0.4898],\n",
      "        [ 0.3427, -0.1527,  0.2004,  ..., -0.3842, -0.5421, -0.6784],\n",
      "        [ 0.2279, -0.1471,  0.2607,  ..., -0.2943, -0.7689, -0.0661],\n",
      "        [ 0.2902,  0.0279,  0.5068,  ..., -0.2260, -0.6080, -0.4051],\n",
      "        [ 0.2588, -0.1658,  0.0357,  ..., -0.3046, -0.4985, -0.7199]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 1.7025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 5.5033\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2854, 1024]), batch.edge_index: torch.Size([2, 8867])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2854, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.2827,  0.0645,  0.2641,  ..., -0.4948, -0.6407, -0.5664],\n",
      "        [ 0.2881,  0.1753,  0.4288,  ..., -0.5652, -0.6045, -0.5630],\n",
      "        [ 0.2985, -0.2441,  0.1205,  ..., -0.3582, -0.7482, -0.5016],\n",
      "        [ 0.3161,  0.0875,  0.3107,  ..., -0.5806, -0.3449, -0.6780],\n",
      "        [ 0.3337,  0.0611,  0.4244,  ..., -0.5459, -0.6108, -0.1281]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 1.8153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 7.3186\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2802, 1024]), batch.edge_index: torch.Size([2, 8800])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2802, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.2668,  0.0871,  0.3107,  ..., -0.3322, -0.1926, -0.5892],\n",
      "        [ 0.3428, -0.0014,  0.6682,  ..., -0.6321, -0.3858, -0.3626],\n",
      "        [ 0.2744,  0.0833,  0.2790,  ..., -0.6371, -0.4449, -0.6226],\n",
      "        [ 0.3945,  0.0615,  0.3867,  ..., -0.5298, -0.4566, -0.4558],\n",
      "        [ 0.0965, -0.0627,  0.3224,  ..., -0.2823, -0.4309, -0.4407]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 1.6906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 9.0092\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2804, 1024]), batch.edge_index: torch.Size([2, 8573])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2804, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.3041,  0.0573,  0.4575,  ..., -0.5686, -0.1946, -0.5967],\n",
      "        [ 0.2456,  0.1383,  0.4430,  ..., -0.1955, -0.5967, -0.4208],\n",
      "        [ 0.3367, -0.1472,  0.0857,  ..., -0.1636, -0.8679, -0.5800],\n",
      "        [ 0.2215,  0.2464,  0.1431,  ..., -0.6139, -0.3824, -0.5148],\n",
      "        [ 0.2453, -0.0729,  0.2741,  ..., -0.4497, -0.5401, -0.5545]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 1.7818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 10.7910\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2423, 1024]), batch.edge_index: torch.Size([2, 6444])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2423, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.2191,  0.2102,  0.4886,  ..., -0.5531, -0.5146, -0.2580],\n",
      "        [ 0.1924,  0.2220,  0.1624,  ..., -0.3235, -0.4914, -0.6537],\n",
      "        [ 0.3377,  0.1252,  0.4028,  ..., -0.4688, -0.5944, -0.3222],\n",
      "        [ 0.3292, -0.2777,  0.3547,  ..., -0.4991, -0.6519, -0.5868],\n",
      "        [ 0.4829,  0.2937,  0.4211,  ..., -0.5163, -0.5608, -0.4707]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 2.3903\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training epochs:  80%|████████  | 4/5 [26:20<06:36, 396.20s/it, avg_loss=1.8830, mean_norm=4.7564, std_norm=2.6219]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 13.1813\n",
      "[DEBUG] Number of embeddings collected: 7\n",
      "[DEBUG] Epoch embeddings shape: torch.Size([19356, 256])\n",
      "[DEBUG] Embeddings norms statistics -> min: 0.4354, max: 9.1650, mean: 4.7564, std: 2.6219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Batch shapes - batch.x: torch.Size([2795, 1024]), batch.edge_index: torch.Size([2, 8560])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2795, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.3277, -0.0101,  0.4154,  ..., -0.3088, -0.5340, -0.5087],\n",
      "        [ 0.3976,  0.2775,  0.2818,  ..., -0.2362, -0.4160, -0.4564],\n",
      "        [ 0.3065,  0.1928,  0.2304,  ..., -0.7395, -0.1649, -0.4074],\n",
      "        [ 0.1729,  0.1074,  0.1990,  ..., -0.1659, -0.5409, -0.4502],\n",
      "        [ 0.1113, -0.0098,  0.2369,  ..., -0.4866, -0.4722, -0.7185]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 1.7487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 1.7487\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2785, 1024]), batch.edge_index: torch.Size([2, 8340])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2785, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.2336, -0.1675,  0.4509,  ..., -0.1411, -0.5777, -0.8033],\n",
      "        [ 0.3440,  0.1273,  0.1850,  ..., -0.6093, -0.4617, -0.6069],\n",
      "        [ 0.3207,  0.0521,  0.2820,  ..., -0.6605, -0.4404, -0.6414],\n",
      "        [ 0.2256,  0.1049,  0.2061,  ..., -0.3810, -0.5818, -0.4300],\n",
      "        [ 0.4286, -0.0547, -0.0583,  ..., -0.5105, -0.6870, -0.7705]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 1.8330\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 3.5817\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2930, 1024]), batch.edge_index: torch.Size([2, 8998])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2930, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.4096,  0.0749,  0.4121,  ..., -0.6657, -0.3841, -0.7085],\n",
      "        [ 0.3127,  0.1978,  0.3142,  ..., -0.8632, -0.4962, -0.8640],\n",
      "        [ 0.6495,  0.2107,  0.1181,  ..., -0.1865, -0.2582, -0.5027],\n",
      "        [ 0.5478,  0.2318,  0.3735,  ..., -0.6707, -0.6845, -0.5810],\n",
      "        [ 0.4532,  0.0515,  0.4222,  ..., -0.3597, -0.4222, -0.6993]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 1.7217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 5.3034\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2797, 1024]), batch.edge_index: torch.Size([2, 8619])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2797, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.3510, -0.1994,  0.2283,  ..., -0.4365, -0.8389, -0.4603],\n",
      "        [ 0.3388,  0.0074,  0.4425,  ..., -0.1792, -0.5969, -0.5290],\n",
      "        [ 0.4168,  0.0289,  0.3785,  ..., -0.3978, -0.4384, -0.4695],\n",
      "        [ 0.3633, -0.0554,  0.1131,  ..., -0.3959, -0.6639, -0.4465],\n",
      "        [ 0.4129,  0.0451,  0.6237,  ..., -0.2535, -0.2577, -0.4858]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 1.6373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 6.9407\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2716, 1024]), batch.edge_index: torch.Size([2, 8338])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2716, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.5027,  0.0290,  0.5306,  ..., -0.5743, -0.3836, -0.8134],\n",
      "        [ 0.3461, -0.0043,  0.5708,  ..., -0.7560, -0.2998, -0.2275],\n",
      "        [ 0.4561,  0.0297,  0.5090,  ..., -0.4550, -0.0548, -0.4251],\n",
      "        [ 0.3477, -0.0216,  0.2632,  ..., -0.4864, -0.5904, -0.3621],\n",
      "        [ 0.5156,  0.0961,  0.4605,  ..., -0.4799, -0.5555, -0.4197]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 1.6771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 8.6178\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2872, 1024]), batch.edge_index: torch.Size([2, 9101])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2872, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.4203, -0.2545,  0.4813,  ..., -0.7020, -0.6237, -0.3962],\n",
      "        [ 0.3759, -0.2042,  0.1762,  ..., -0.3605, -0.4915, -0.5231],\n",
      "        [ 0.4724, -0.0147,  0.2795,  ..., -0.4084, -0.5542, -0.5146],\n",
      "        [ 0.4535, -0.1075,  0.4356,  ..., -0.5183, -0.6925, -0.4122],\n",
      "        [ 0.6190, -0.1299,  0.4555,  ..., -0.6974, -0.2556, -0.5016]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 1.5323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] Accumulated loss so far: 10.1500\n",
      "[DEBUG] Batch shapes - batch.x: torch.Size([2444, 1024]), batch.edge_index: torch.Size([2, 6446])\n",
      "[DEBUG] Model output (z) shape: torch.Size([2444, 256])\n",
      "[DEBUG] First 5 embeddings: tensor([[ 0.2809,  0.0512,  0.5101,  ..., -0.6815, -0.4657, -0.6115],\n",
      "        [ 0.4843, -0.0774,  0.4034,  ..., -0.6615, -0.3689, -0.7927],\n",
      "        [ 0.2194,  0.0791,  0.3112,  ..., -0.3385, -0.4928, -0.3674],\n",
      "        [ 0.7366, -0.0839,  0.3669,  ..., -0.7824, -0.4686, -0.7601],\n",
      "        [ 0.2341,  0.1427,  0.5700,  ..., -0.4824, -0.4742, -0.4194]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "[DEBUG] Loss value for this batch: 2.2345\n"
     ]
    }
   ],
   "source": [
    "train_in_cpu(model, train_loader, optimizer, num_epochs=5, loss_fn=unsupervised_loss, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save embeddings as .npy file\n",
    "\n",
    "## 1) Get the device from any parameter in the model\n",
    "#device = next(model.parameters()).device\n",
    "#\n",
    "## 2) Now move your data.x and data.edge_index to that device:\n",
    "#data_x = data.x.to(device)\n",
    "#data_edge_index = data.edge_index.to(device)\n",
    "#\n",
    "## 3) Forward pass with torch.no_grad():\n",
    "#with torch.no_grad():\n",
    "#    embeddings = model(data_x, data_edge_index)\n",
    "#\n",
    "#embeddings_np = embeddings.cpu().numpy()\n",
    "#np.save(\"../data/graphsage_embeddings.npy\", embeddings_np)\n",
    "#print(\"Embeddings saved to graphsage_embeddings.npy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAGE embeddings added to G under 'SAGE_embedding' attribute.\n"
     ]
    }
   ],
   "source": [
    "## Add Graph_SAGE embeddings to the baseline graph\n",
    "#\n",
    "## 1) Move data to the same device as the model\n",
    "#device = next(model.parameters()).device\n",
    "#data_x = data.x.to(device)\n",
    "#data_edge_index = data.edge_index.to(device)\n",
    "#\n",
    "## 2) Obtain final embeddings from the trained model\n",
    "#with torch.no_grad():\n",
    "#    final_emb = model(data_x, data_edge_index)  # shape [num_nodes, embedding_dim]\n",
    "#    final_emb_np = final_emb.cpu().numpy()\n",
    "#\n",
    "## 3) Add them back to the cleaned_G graph\n",
    "#list_of_nodes = list(G.nodes())  # Must match the node ordering in data\n",
    "#for i, node in enumerate(list_of_nodes):\n",
    "#    # Store as a NumPy array (or you could store as a list if you prefer)\n",
    "#    G.nodes[node][\"SAGE_embedding\"] = final_emb_np[i]\n",
    "#\n",
    "#print(\"SAGE embeddings added to G under 'SAGE_embedding' attribute.\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open(f\"../data/multihop_graph_w_sage{num_epochs}_embeddings_1hop.pkl\", \"wb\") as f:\n",
    "#    pickle.dump(G, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to graphsage_model.pth\n"
     ]
    }
   ],
   "source": [
    "## Save the model's state_dict to disk\n",
    "#torch.save(model.state_dict(), f\"../data/graphsage_{num_epochs}_model_1hop.pth\")\n",
    "#print(\"Model saved to graphsage_model.pth\")\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New node embedding shape: torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "#def get_new_node_embedding(model, new_feature, device, self_loop=True):\n",
    "#    \"\"\"\n",
    "#    Generate an embedding for a new node using the trained GraphSAGE model.\n",
    "#    \n",
    "#    Parameters:\n",
    "#      model (torch.nn.Module): The trained GraphSAGE model.\n",
    "#      new_feature (torch.Tensor): The new node's initial features of shape (1024,).\n",
    "#      device (torch.device): The device (e.g., cuda) on which the model is located.\n",
    "#      self_loop (bool, default=True): If True, adds a self-loop edge (node connected to itself).\n",
    "#                                      This simulates neighbor aggregation when no neighbors exist.\n",
    "#    \n",
    "#    Returns:\n",
    "#      torch.Tensor: The new node's embedding of shape (out_channels,).\n",
    "#    \"\"\"\n",
    "#    # Set the model to evaluation mode.\n",
    "#    model.eval()\n",
    "#    \n",
    "#    # Move the new node's features to the correct device.\n",
    "#    new_feature = new_feature.to(device)\n",
    "#    \n",
    "#    if self_loop:\n",
    "#        # Create a self-loop edge_index. This indicates that the node is connected to itself.\n",
    "#        # The edge_index tensor must have shape [2, num_edges]; here we create a single edge (0,0).\n",
    "#        edge_index = torch.tensor([[0], [0]], dtype=torch.long, device=device)\n",
    "#    else:\n",
    "#        # Alternatively, if you prefer no edges, you can pass an empty edge_index.\n",
    "#        # Note: Without a self-loop, the model may not transform the features as intended.\n",
    "#        edge_index = torch.empty((2, 0), dtype=torch.long, device=device)\n",
    "#    \n",
    "#    # GraphSAGE expects a batch dimension, so unsqueeze new_feature to shape [1, 1024].\n",
    "#    with torch.no_grad():\n",
    "#        new_embedding = model(new_feature.unsqueeze(0), edge_index)\n",
    "#    \n",
    "#    # Remove the batch dimension to return a tensor of shape [out_channels].\n",
    "#    return new_embedding.squeeze(0)\n",
    "#\n",
    "## Example usage:\n",
    "## Assuming 'model' is your trained GraphSAGE and you have a new node feature vector of size 1024.\n",
    "#new_feature = torch.randn(1024)  # Replace with the actual feature vector for the new node.\n",
    "#device = next(model.parameters()).device  # Get the device from the model.\n",
    "#new_node_embedding = get_new_node_embedding(model, new_feature, device, self_loop=True)\n",
    "#print(\"New node embedding shape:\", new_node_embedding.shape)\n",
    "#"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311_graphsage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
