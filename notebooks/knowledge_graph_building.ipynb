{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "from pathlib import Path\n",
    "from ollama import Client\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import pynvml\n",
    "import time\n",
    "import subprocess\n",
    "\n",
    "# Initialize Ollama client\n",
    "client = Client(host='http://localhost:11434')\n",
    "\n",
    "# Load NER prompt template\n",
    "ner_prompt_path = Path('../prompts') / 'entity_extraction.yaml'\n",
    "with open(ner_prompt_path, 'r', encoding='utf-8') as file:\n",
    "    ner_prompt_content = yaml.safe_load(file)\n",
    "ner_prompt = ner_prompt_content['entity_extraction']\n",
    "\n",
    "# Load summarization prompt template\n",
    "sum_prompt_path = Path('../prompts') / 'article_summarization.yaml'\n",
    "with open(sum_prompt_path, 'r', encoding='utf-8') as file:\n",
    "    sum_prompt_content = yaml.safe_load(file)\n",
    "sum_prompt = sum_prompt_content['article_summarization']\n",
    "\n",
    "# Example text to process\n",
    "sample_text = \"\"\"\n",
    "Apple announced its new iPhone 15 on September 12, 2023. \n",
    "Tim Cook presented the event at Apple Park in Cupertino, California. \n",
    "The event was also streamed live on YouTube, where millions of viewers tuned in.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gpu_temperature():\n",
    "    # Run nvidia-smi to query GPU temperature\n",
    "    result = subprocess.run(\n",
    "        [\"nvidia-smi\", \"--query-gpu=temperature.gpu\", \"--format=csv,noheader\"],\n",
    "        stdout=subprocess.PIPE,\n",
    "        text=True\n",
    "    )\n",
    "    # Parse and return temperature of GPU 0\n",
    "    return int(result.stdout.strip().split('\\n')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gpu_temperature_rest_time():\n",
    "    if get_gpu_temperature() >= 80:\n",
    "        return 100\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_json(text):\n",
    "    # Search for a block that starts with '{' and ends with '}'.\n",
    "    # The re.DOTALL flag allows the '.' to match newline characters.\n",
    "    match = re.search(r'\\{.*\\}', text, re.DOTALL)\n",
    "    if match:\n",
    "        json_str = match.group(0)\n",
    "        try:\n",
    "            # Try to decode the JSON string into a Python object\n",
    "            return json.loads(json_str)\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(\"Error decoding JSON:\", e)\n",
    "            return None\n",
    "    else:\n",
    "        print(\"No JSON block found in the text.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ollama_summary(article_body, sum_prompt, model=\"gemma3:27b-it-q8_0\"):\n",
    "# Prepare the messages with both system and user prompts\n",
    "    sum_messages = [\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': sum_prompt['system_prompt']\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': sum_prompt['user_prompt_template'].replace(\"{text_to_process}\", article_body)\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Call Ollama API\n",
    "    response = client.chat(\n",
    "        model=model,\n",
    "        messages=sum_messages,\n",
    "        options={\"temperature\":0.4}\n",
    "    )\n",
    "\n",
    "    # Get the raw response content\n",
    "    summary = response['message']['content']\n",
    "\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ollama_entities(article_summary, ner_prompt, model=\"gemma3:27b-it-q8_0\"):\n",
    "# Prepare the messages with both system and user prompts\n",
    "    ner_messages = [\n",
    "        {\n",
    "            'role': 'system',\n",
    "            'content': ner_prompt['system_prompt']\n",
    "        },\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': ner_prompt['user_prompt_template'].replace(\"{text_to_process}\", article_summary)\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Call Ollama API\n",
    "    response = client.chat(\n",
    "        model=model,\n",
    "        messages=ner_messages,\n",
    "       # options={\"temperature\":0.2}\n",
    "    )\n",
    "\n",
    "    # Get the raw response content\n",
    "    entities_json = extract_json(response['message']['content'])\n",
    "\n",
    "    return entities_json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load baseline graph\n",
    "with open(\"../data/MultiHop_graph_w_sem_embeddings.pkl\", \"rb\") as f:\n",
    "    G = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to corpus file\n",
    "multihop_corpus_path = os.path.join(\"..\", \"data\", \"Multi-hop_RAG_dataset\", \"corpus.json\")\n",
    "\n",
    "# Read JSON\n",
    "with open(multihop_corpus_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    corpus = json.load(f)\n",
    "\n",
    "# Convert corpus data into df\n",
    "corpus_as_df = pd.DataFrame(corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing article:  0\n",
      "-----> Summary for article 0 finished...\n",
      "-----> Entity extraction for article 0 finished...\n",
      "Processing article:  1\n",
      "-----> Summary for article 1 finished...\n",
      "-----> Entity extraction for article 1 finished...\n",
      "Processing article:  2\n",
      "== Pausing code execution to cool down GPU... (83) ==\n",
      "-----> Summary for article 2 finished...\n",
      "-----> Entity extraction for article 2 finished...\n",
      "Processing article:  3\n",
      "-----> Summary for article 3 finished...\n",
      "== Pausing code execution to cool down GPU... (80) ==\n",
      "-----> Entity extraction for article 3 finished...\n",
      "Processing article:  4\n",
      "-----> Summary for article 4 finished...\n",
      "-----> Entity extraction for article 4 finished...\n",
      "Processing article:  5\n",
      "== Pausing code execution to cool down GPU... (83) ==\n",
      "-----> Summary for article 5 finished...\n",
      "-----> Entity extraction for article 5 finished...\n",
      "Processing article:  6\n",
      "-----> Summary for article 6 finished...\n",
      "-----> Entity extraction for article 6 finished...\n",
      "Processing article:  7\n",
      "-----> Summary for article 7 finished...\n",
      "== Pausing code execution to cool down GPU... (80) ==\n",
      "-----> Entity extraction for article 7 finished...\n",
      "Processing article:  8\n",
      "== Pausing code execution to cool down GPU... (83) ==\n",
      "-----> Summary for article 8 finished...\n",
      "-----> Entity extraction for article 8 finished...\n",
      "Processing article:  9\n",
      "-----> Summary for article 9 finished...\n",
      "-----> Entity extraction for article 9 finished...\n",
      "Processing article:  10\n",
      "== Pausing code execution to cool down GPU... (83) ==\n",
      "-----> Summary for article 10 finished...\n",
      "-----> Entity extraction for article 10 finished...\n",
      "Processing article:  11\n",
      "-----> Summary for article 11 finished...\n",
      "-----> Entity extraction for article 11 finished...\n",
      "Processing article:  12\n",
      "== Pausing code execution to cool down GPU... (82) ==\n",
      "-----> Summary for article 12 finished...\n",
      "-----> Entity extraction for article 12 finished...\n",
      "Processing article:  13\n",
      "-----> Summary for article 13 finished...\n",
      "-----> Entity extraction for article 13 finished...\n",
      "Processing article:  14\n",
      "-----> Summary for article 14 finished...\n",
      "-----> Entity extraction for article 14 finished...\n",
      "Processing article:  15\n",
      "== Pausing code execution to cool down GPU... (83) ==\n",
      "-----> Summary for article 15 finished...\n",
      "-----> Entity extraction for article 15 finished...\n",
      "Processing article:  16\n",
      "-----> Summary for article 16 finished...\n",
      "-----> Entity extraction for article 16 finished...\n",
      "Processing article:  17\n",
      "== Pausing code execution to cool down GPU... (81) ==\n",
      "-----> Summary for article 17 finished...\n",
      "-----> Entity extraction for article 17 finished...\n",
      "Processing article:  18\n",
      "-----> Summary for article 18 finished...\n",
      "-----> Entity extraction for article 18 finished...\n",
      "Processing article:  19\n",
      "== Pausing code execution to cool down GPU... (81) ==\n",
      "-----> Summary for article 19 finished...\n",
      "-----> Entity extraction for article 19 finished...\n",
      "Processing article:  20\n",
      "-----> Summary for article 20 finished...\n",
      "-----> Entity extraction for article 20 finished...\n",
      "Processing article:  21\n",
      "-----> Summary for article 21 finished...\n",
      "-----> Entity extraction for article 21 finished...\n",
      "Processing article:  22\n",
      "== Pausing code execution to cool down GPU... (79) ==\n",
      "-----> Summary for article 22 finished...\n",
      "== Pausing code execution to cool down GPU... (81) ==\n",
      "-----> Entity extraction for article 22 finished...\n",
      "Processing article:  23\n",
      "-----> Summary for article 23 finished...\n",
      "-----> Entity extraction for article 23 finished...\n",
      "Processing article:  24\n",
      "-----> Summary for article 24 finished...\n",
      "-----> Entity extraction for article 24 finished...\n",
      "Processing article:  25\n",
      "== Pausing code execution to cool down GPU... (83) ==\n",
      "-----> Summary for article 25 finished...\n",
      "-----> Entity extraction for article 25 finished...\n",
      "Processing article:  26\n",
      "-----> Summary for article 26 finished...\n",
      "== Pausing code execution to cool down GPU... (79) ==\n",
      "-----> Entity extraction for article 26 finished...\n",
      "Processing article:  27\n",
      "== Pausing code execution to cool down GPU... (83) ==\n",
      "-----> Summary for article 27 finished...\n",
      "-----> Entity extraction for article 27 finished...\n",
      "Processing article:  28\n",
      "-----> Summary for article 28 finished...\n",
      "== Pausing code execution to cool down GPU... (80) ==\n",
      "-----> Entity extraction for article 28 finished...\n",
      "Processing article:  29\n",
      "== Pausing code execution to cool down GPU... (80) ==\n",
      "-----> Summary for article 29 finished...\n",
      "-----> Entity extraction for article 29 finished...\n",
      "Processing article:  30\n",
      "-----> Summary for article 30 finished...\n",
      "-----> Entity extraction for article 30 finished...\n",
      "Processing article:  31\n",
      "== Pausing code execution to cool down GPU... (81) ==\n",
      "-----> Summary for article 31 finished...\n",
      "-----> Entity extraction for article 31 finished...\n",
      "Processing article:  32\n",
      "-----> Summary for article 32 finished...\n",
      "-----> Entity extraction for article 32 finished...\n",
      "Processing article:  33\n",
      "-----> Summary for article 33 finished...\n",
      "-----> Entity extraction for article 33 finished...\n",
      "Processing article:  34\n",
      "== Pausing code execution to cool down GPU... (83) ==\n",
      "-----> Summary for article 34 finished...\n",
      "-----> Entity extraction for article 34 finished...\n",
      "Processing article:  35\n",
      "-----> Summary for article 35 finished...\n",
      "== Pausing code execution to cool down GPU... (80) ==\n",
      "-----> Entity extraction for article 35 finished...\n",
      "Processing article:  36\n",
      "-----> Summary for article 36 finished...\n",
      "-----> Entity extraction for article 36 finished...\n",
      "Processing article:  37\n",
      "== Pausing code execution to cool down GPU... (79) ==\n",
      "-----> Summary for article 37 finished...\n",
      "== Pausing code execution to cool down GPU... (82) ==\n",
      "-----> Entity extraction for article 37 finished...\n",
      "Processing article:  38\n",
      "-----> Summary for article 38 finished...\n",
      "-----> Entity extraction for article 38 finished...\n",
      "Processing article:  39\n",
      "-----> Summary for article 39 finished...\n",
      "-----> Entity extraction for article 39 finished...\n",
      "Processing article:  40\n",
      "== Pausing code execution to cool down GPU... (81) ==\n",
      "-----> Summary for article 40 finished...\n",
      "-----> Entity extraction for article 40 finished...\n",
      "Processing article:  41\n",
      "-----> Summary for article 41 finished...\n",
      "== Pausing code execution to cool down GPU... (81) ==\n",
      "-----> Entity extraction for article 41 finished...\n",
      "Processing article:  42\n",
      "-----> Summary for article 42 finished...\n",
      "-----> Entity extraction for article 42 finished...\n",
      "Processing article:  43\n",
      "-----> Summary for article 43 finished...\n",
      "-----> Entity extraction for article 43 finished...\n",
      "Processing article:  44\n",
      "== Pausing code execution to cool down GPU... (83) ==\n",
      "-----> Summary for article 44 finished...\n",
      "-----> Entity extraction for article 44 finished...\n",
      "Processing article:  45\n",
      "-----> Summary for article 45 finished...\n",
      "-----> Entity extraction for article 45 finished...\n",
      "Processing article:  46\n",
      "== Pausing code execution to cool down GPU... (80) ==\n",
      "-----> Summary for article 46 finished...\n",
      "== Pausing code execution to cool down GPU... (81) ==\n",
      "-----> Entity extraction for article 46 finished...\n",
      "Processing article:  47\n",
      "-----> Summary for article 47 finished...\n",
      "-----> Entity extraction for article 47 finished...\n",
      "Processing article:  48\n",
      "-----> Summary for article 48 finished...\n",
      "-----> Entity extraction for article 48 finished...\n",
      "Processing article:  49\n",
      "== Pausing code execution to cool down GPU... (82) ==\n",
      "-----> Summary for article 49 finished...\n",
      "Error decoding JSON: Expecting ',' delimiter: line 11239 column 6 (char 263150)\n",
      "Error decoding JSON: Expecting ',' delimiter: line 11239 column 6 (char 263150)\n",
      "Error decoding JSON: Expecting ',' delimiter: line 11239 column 6 (char 263150)\n",
      "----------> JSON not extracted for:  49\n",
      "-----> Entity extraction for article 49 finished...\n",
      "Processing article:  50\n",
      "-----> Summary for article 50 finished...\n",
      "-----> Entity extraction for article 50 finished...\n",
      "Processing article:  51\n",
      "-----> Summary for article 51 finished...\n",
      "-----> Entity extraction for article 51 finished...\n",
      "Processing article:  52\n",
      "-----> Summary for article 52 finished...\n",
      "-----> Entity extraction for article 52 finished...\n",
      "Processing article:  53\n",
      "-----> Summary for article 53 finished...\n",
      "-----> Entity extraction for article 53 finished...\n",
      "Processing article:  54\n",
      "-----> Summary for article 54 finished...\n",
      "-----> Entity extraction for article 54 finished...\n",
      "Processing article:  55\n",
      "-----> Summary for article 55 finished...\n",
      "-----> Entity extraction for article 55 finished...\n",
      "Processing article:  56\n",
      "-----> Summary for article 56 finished...\n",
      "-----> Entity extraction for article 56 finished...\n",
      "Processing article:  57\n",
      "-----> Summary for article 57 finished...\n",
      "Error decoding JSON: Extra data: line 19 column 4 (char 384)\n",
      "Error decoding JSON: Extra data: line 19 column 4 (char 384)\n",
      "Error decoding JSON: Extra data: line 19 column 4 (char 384)\n",
      "----------> JSON not extracted for:  57\n",
      "-----> Entity extraction for article 57 finished...\n",
      "Processing article:  58\n",
      "-----> Summary for article 58 finished...\n",
      "-----> Entity extraction for article 58 finished...\n",
      "Processing article:  59\n",
      "-----> Summary for article 59 finished...\n",
      "-----> Entity extraction for article 59 finished...\n",
      "Processing article:  60\n",
      "-----> Summary for article 60 finished...\n",
      "-----> Entity extraction for article 60 finished...\n",
      "Processing article:  61\n",
      "-----> Summary for article 61 finished...\n",
      "-----> Entity extraction for article 61 finished...\n",
      "Processing article:  62\n",
      "-----> Summary for article 62 finished...\n",
      "-----> Entity extraction for article 62 finished...\n",
      "Processing article:  63\n",
      "-----> Summary for article 63 finished...\n",
      "-----> Entity extraction for article 63 finished...\n",
      "Processing article:  64\n",
      "-----> Summary for article 64 finished...\n",
      "-----> Entity extraction for article 64 finished...\n",
      "Processing article:  65\n",
      "-----> Summary for article 65 finished...\n",
      "-----> Entity extraction for article 65 finished...\n",
      "Processing article:  66\n",
      "-----> Summary for article 66 finished...\n",
      "-----> Entity extraction for article 66 finished...\n",
      "Processing article:  67\n",
      "-----> Summary for article 67 finished...\n",
      "-----> Entity extraction for article 67 finished...\n",
      "Processing article:  68\n",
      "-----> Summary for article 68 finished...\n",
      "-----> Entity extraction for article 68 finished...\n",
      "Processing article:  69\n",
      "-----> Summary for article 69 finished...\n",
      "-----> Entity extraction for article 69 finished...\n",
      "Processing article:  70\n",
      "-----> Summary for article 70 finished...\n",
      "-----> Entity extraction for article 70 finished...\n",
      "Processing article:  71\n",
      "-----> Summary for article 71 finished...\n",
      "-----> Entity extraction for article 71 finished...\n",
      "Processing article:  72\n",
      "-----> Summary for article 72 finished...\n",
      "-----> Entity extraction for article 72 finished...\n",
      "Processing article:  73\n",
      "-----> Summary for article 73 finished...\n",
      "-----> Entity extraction for article 73 finished...\n",
      "Processing article:  74\n",
      "-----> Summary for article 74 finished...\n",
      "-----> Entity extraction for article 74 finished...\n",
      "Processing article:  75\n",
      "-----> Summary for article 75 finished...\n",
      "-----> Entity extraction for article 75 finished...\n",
      "Processing article:  76\n",
      "-----> Summary for article 76 finished...\n",
      "-----> Entity extraction for article 76 finished...\n",
      "Processing article:  77\n",
      "-----> Summary for article 77 finished...\n",
      "-----> Entity extraction for article 77 finished...\n",
      "Processing article:  78\n",
      "-----> Summary for article 78 finished...\n",
      "-----> Entity extraction for article 78 finished...\n",
      "Processing article:  79\n",
      "-----> Summary for article 79 finished...\n",
      "-----> Entity extraction for article 79 finished...\n",
      "Processing article:  80\n",
      "-----> Summary for article 80 finished...\n",
      "-----> Entity extraction for article 80 finished...\n",
      "Processing article:  81\n",
      "-----> Summary for article 81 finished...\n",
      "-----> Entity extraction for article 81 finished...\n",
      "Processing article:  82\n",
      "-----> Summary for article 82 finished...\n",
      "-----> Entity extraction for article 82 finished...\n",
      "Processing article:  83\n",
      "-----> Summary for article 83 finished...\n",
      "-----> Entity extraction for article 83 finished...\n",
      "Processing article:  84\n",
      "-----> Summary for article 84 finished...\n",
      "-----> Entity extraction for article 84 finished...\n",
      "Processing article:  85\n",
      "-----> Summary for article 85 finished...\n",
      "-----> Entity extraction for article 85 finished...\n",
      "Processing article:  86\n",
      "-----> Summary for article 86 finished...\n",
      "-----> Entity extraction for article 86 finished...\n",
      "Processing article:  87\n",
      "-----> Summary for article 87 finished...\n",
      "-----> Entity extraction for article 87 finished...\n",
      "Processing article:  88\n",
      "-----> Summary for article 88 finished...\n",
      "-----> Entity extraction for article 88 finished...\n",
      "Processing article:  89\n",
      "-----> Summary for article 89 finished...\n",
      "-----> Entity extraction for article 89 finished...\n",
      "Processing article:  90\n",
      "-----> Summary for article 90 finished...\n",
      "Error decoding JSON: Expecting ',' delimiter: line 13846 column 6 (char 261989)\n",
      "Error decoding JSON: Expecting ',' delimiter: line 13846 column 6 (char 261989)\n",
      "Error decoding JSON: Expecting ',' delimiter: line 13846 column 6 (char 261989)\n",
      "----------> JSON not extracted for:  90\n",
      "-----> Entity extraction for article 90 finished...\n",
      "Processing article:  91\n",
      "-----> Summary for article 91 finished...\n",
      "-----> Entity extraction for article 91 finished...\n",
      "Processing article:  92\n",
      "-----> Summary for article 92 finished...\n",
      "-----> Entity extraction for article 92 finished...\n",
      "Processing article:  93\n",
      "-----> Summary for article 93 finished...\n",
      "-----> Entity extraction for article 93 finished...\n",
      "Processing article:  94\n",
      "-----> Summary for article 94 finished...\n",
      "Error decoding JSON: Extra data: line 4 column 4 (char 61)\n",
      "Error decoding JSON: Extra data: line 5 column 4 (char 91)\n",
      "Error decoding JSON: Extra data: line 5 column 4 (char 91)\n",
      "----------> JSON not extracted for:  94\n",
      "-----> Entity extraction for article 94 finished...\n",
      "Processing article:  95\n",
      "-----> Summary for article 95 finished...\n",
      "-----> Entity extraction for article 95 finished...\n",
      "Processing article:  96\n",
      "-----> Summary for article 96 finished...\n",
      "-----> Entity extraction for article 96 finished...\n",
      "Processing article:  97\n",
      "-----> Summary for article 97 finished...\n",
      "-----> Entity extraction for article 97 finished...\n",
      "Processing article:  98\n",
      "-----> Summary for article 98 finished...\n",
      "-----> Entity extraction for article 98 finished...\n",
      "Processing article:  99\n",
      "-----> Summary for article 99 finished...\n",
      "-----> Entity extraction for article 99 finished...\n",
      "Processing article:  100\n",
      "-----> Summary for article 100 finished...\n",
      "-----> Entity extraction for article 100 finished...\n",
      "Processing article:  101\n",
      "-----> Summary for article 101 finished...\n",
      "-----> Entity extraction for article 101 finished...\n",
      "Processing article:  102\n",
      "-----> Summary for article 102 finished...\n",
      "-----> Entity extraction for article 102 finished...\n",
      "Processing article:  103\n",
      "-----> Summary for article 103 finished...\n",
      "-----> Entity extraction for article 103 finished...\n",
      "Processing article:  104\n",
      "-----> Summary for article 104 finished...\n",
      "-----> Entity extraction for article 104 finished...\n",
      "Processing article:  105\n",
      "-----> Summary for article 105 finished...\n",
      "-----> Entity extraction for article 105 finished...\n",
      "Processing article:  106\n",
      "-----> Summary for article 106 finished...\n",
      "-----> Entity extraction for article 106 finished...\n",
      "Processing article:  107\n",
      "-----> Summary for article 107 finished...\n",
      "-----> Entity extraction for article 107 finished...\n",
      "Processing article:  108\n",
      "-----> Summary for article 108 finished...\n",
      "-----> Entity extraction for article 108 finished...\n",
      "Processing article:  109\n",
      "-----> Summary for article 109 finished...\n",
      "-----> Entity extraction for article 109 finished...\n",
      "Processing article:  110\n",
      "-----> Summary for article 110 finished...\n",
      "-----> Entity extraction for article 110 finished...\n",
      "Processing article:  111\n",
      "-----> Summary for article 111 finished...\n",
      "-----> Entity extraction for article 111 finished...\n",
      "Processing article:  112\n",
      "-----> Summary for article 112 finished...\n",
      "-----> Entity extraction for article 112 finished...\n",
      "Processing article:  113\n",
      "-----> Summary for article 113 finished...\n",
      "-----> Entity extraction for article 113 finished...\n",
      "Processing article:  114\n",
      "-----> Summary for article 114 finished...\n",
      "Error decoding JSON: Extra data: line 6 column 4 (char 89)\n",
      "Error decoding JSON: Extra data: line 6 column 4 (char 89)\n",
      "Error decoding JSON: Extra data: line 6 column 4 (char 89)\n",
      "----------> JSON not extracted for:  114\n",
      "-----> Entity extraction for article 114 finished...\n",
      "Processing article:  115\n",
      "-----> Summary for article 115 finished...\n",
      "-----> Entity extraction for article 115 finished...\n",
      "Processing article:  116\n",
      "-----> Summary for article 116 finished...\n",
      "-----> Entity extraction for article 116 finished...\n",
      "Processing article:  117\n",
      "-----> Summary for article 117 finished...\n",
      "-----> Entity extraction for article 117 finished...\n",
      "Processing article:  118\n",
      "-----> Summary for article 118 finished...\n",
      "Error decoding JSON: Extra data: line 6 column 4 (char 122)\n",
      "Error decoding JSON: Extra data: line 6 column 4 (char 122)\n",
      "Error decoding JSON: Extra data: line 6 column 4 (char 122)\n",
      "----------> JSON not extracted for:  118\n",
      "-----> Entity extraction for article 118 finished...\n",
      "Processing article:  119\n",
      "-----> Summary for article 119 finished...\n",
      "-----> Entity extraction for article 119 finished...\n",
      "Processing article:  120\n",
      "-----> Summary for article 120 finished...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 37\u001b[39m\n\u001b[32m     34\u001b[39m     time.sleep(gpu_temperature_rest_time())\n\u001b[32m     36\u001b[39m \u001b[38;5;66;03m# Extract entities \u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m json_entities = \u001b[43mget_ollama_entities\u001b[49m\u001b[43m(\u001b[49m\u001b[43mllm_summary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mner_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     38\u001b[39m while_count += \u001b[32m1\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# If after three attempts the output is not valid... \u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mget_ollama_entities\u001b[39m\u001b[34m(article_summary, ner_prompt, model)\u001b[39m\n\u001b[32m      3\u001b[39m ner_messages = [\n\u001b[32m      4\u001b[39m     {\n\u001b[32m      5\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m     11\u001b[39m     }\n\u001b[32m     12\u001b[39m ]\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# Call Ollama API\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mner_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# options={\"temperature\":0.2}\u001b[39;49;00m\n\u001b[32m     19\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[38;5;66;03m# Get the raw response content\u001b[39;00m\n\u001b[32m     22\u001b[39m entities_json = extract_json(response[\u001b[33m'\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.6/envs/graphsage/lib/python3.11/site-packages/ollama/_client.py:333\u001b[39m, in \u001b[36mClient.chat\u001b[39m\u001b[34m(self, model, messages, tools, stream, format, options, keep_alive)\u001b[39m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchat\u001b[39m(\n\u001b[32m    290\u001b[39m   \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    291\u001b[39m   model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    298\u001b[39m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    299\u001b[39m ) -> Union[ChatResponse, Iterator[ChatResponse]]:\n\u001b[32m    300\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    301\u001b[39m \u001b[33;03m  Create a chat response using the requested model.\u001b[39;00m\n\u001b[32m    302\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    331\u001b[39m \u001b[33;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001b[39;00m\n\u001b[32m    332\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m    \u001b[49m\u001b[43mChatResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/api/chat\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_copy_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_copy_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m      \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.6/envs/graphsage/lib/python3.11/site-packages/ollama/_client.py:178\u001b[39m, in \u001b[36mClient._request\u001b[39m\u001b[34m(self, cls, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**part)\n\u001b[32m    176\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.json())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.6/envs/graphsage/lib/python3.11/site-packages/ollama/_client.py:118\u001b[39m, in \u001b[36mClient._request_raw\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_request_raw\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    117\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     r = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m     r.raise_for_status()\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.6/envs/graphsage/lib/python3.11/site-packages/httpx/_client.py:825\u001b[39m, in \u001b[36mClient.request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m    810\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m    812\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m    813\u001b[39m     method=method,\n\u001b[32m    814\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    823\u001b[39m     extensions=extensions,\n\u001b[32m    824\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.6/envs/graphsage/lib/python3.11/site-packages/httpx/_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.6/envs/graphsage/lib/python3.11/site-packages/httpx/_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.6/envs/graphsage/lib/python3.11/site-packages/httpx/_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.6/envs/graphsage/lib/python3.11/site-packages/httpx/_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.6/envs/graphsage/lib/python3.11/site-packages/httpx/_transports/default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[32m    255\u001b[39m     status_code=resp.status,\n\u001b[32m    256\u001b[39m     headers=resp.headers,\n\u001b[32m    257\u001b[39m     stream=ResponseStream(resp.stream),\n\u001b[32m    258\u001b[39m     extensions=resp.extensions,\n\u001b[32m    259\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.6/envs/graphsage/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    253\u001b[39m         closing = \u001b[38;5;28mself\u001b[39m._assign_requests_to_connections()\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n\u001b[32m    260\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.6/envs/graphsage/lib/python3.11/site-packages/httpcore/_sync/connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    232\u001b[39m connection = pool_request.wait_for_connection(timeout=timeout)\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n\u001b[32m    244\u001b[39m     pool_request.clear_connection()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.6/envs/graphsage/lib/python3.11/site-packages/httpcore/_sync/connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28mself\u001b[39m._connect_failed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.6/envs/graphsage/lib/python3.11/site-packages/httpcore/_sync/http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    134\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[33m\"\u001b[39m\u001b[33mresponse_closed\u001b[39m\u001b[33m\"\u001b[39m, logger, request) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.6/envs/graphsage/lib/python3.11/site-packages/httpcore/_sync/http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n\u001b[32m    114\u001b[39m network_stream = \u001b[38;5;28mself\u001b[39m._network_stream\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.6/envs/graphsage/lib/python3.11/site-packages/httpcore/_sync/http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    174\u001b[39m timeout = timeouts.get(\u001b[33m\"\u001b[39m\u001b[33mread\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n\u001b[32m    179\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.6/envs/graphsage/lib/python3.11/site-packages/httpcore/_sync/http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    214\u001b[39m     event = \u001b[38;5;28mself\u001b[39m._h11_state.next_event()\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n\u001b[32m    229\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data == \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._h11_state.their_state == h11.SEND_RESPONSE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.6/envs/graphsage/lib/python3.11/site-packages/httpcore/_backends/sync.py:128\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    126\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_exceptions(exc_map):\n\u001b[32m    127\u001b[39m     \u001b[38;5;28mself\u001b[39m._sock.settimeout(timeout)\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_bytes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Initialize dictionary to store detected entities and counter variable\n",
    "entities_dict = {} \n",
    "\n",
    "# For each node in the graph...\n",
    "for node, data in G.nodes(data=True):\n",
    "\n",
    "    # If the node is of type \"article\"...\n",
    "    if data[\"type\"] == 'article':\n",
    "        \n",
    "        print(\"Processing article: \", node)\n",
    "        \n",
    "        # Retrieve article body \n",
    "        article_body = corpus_as_df.iloc[node][\"body\"]\n",
    "\n",
    "        # Check GPU temperature and wait if necessary \n",
    "        while gpu_temperature_rest_time() != 0:\n",
    "            print(f\"== Pausing code execution to cool down GPU... ({get_gpu_temperature()}) ==\")\n",
    "            time.sleep(gpu_temperature_rest_time())\n",
    "\n",
    "        # Generate LLM summary of article for entity extraction \n",
    "        llm_summary = get_ollama_summary(article_body, sum_prompt)\n",
    "        print(f\"-----> Summary for article {node} finished...\")\n",
    "\n",
    "       # Initialize entity extraction loop tracking variables \n",
    "        json_entities = None\n",
    "        while_count = 0\n",
    "\n",
    "        # While we don't have a valid Json output for entities... \n",
    "        while json_entities is None:\n",
    "\n",
    "            # Check GPU temperature and wait if necessary \n",
    "            while gpu_temperature_rest_time() != 0:\n",
    "                print(f\"== Pausing code execution to cool down GPU... ({get_gpu_temperature()}) ==\")\n",
    "                time.sleep(gpu_temperature_rest_time())\n",
    "\n",
    "            # Extract entities \n",
    "            json_entities = get_ollama_entities(llm_summary, ner_prompt)\n",
    "            while_count += 1\n",
    "\n",
    "            # If after three attempts the output is not valid... \n",
    "            if while_count >= 3:\n",
    "                # Exit loop and skip  \n",
    "                print(\"----------> JSON not extracted for: \", node)\n",
    "                break\n",
    "        print(f\"-----> Entity extraction for article {node} finished...\")\n",
    "\n",
    "        # Include entities and summary in \"entities_dict\" \n",
    "        entities_dict[node] ={\"entities\":json_entities, \"summary\":llm_summary}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/extracted_entities_A.pkl\", \"wb\") as f:\n",
    "    pickle.dump(entities_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['0_chunk_0', '0_chunk_1']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify entity citations in chunks\n",
    "\n",
    "# for each article in the multi-hop dataset\n",
    "for article_id in range(610):\n",
    "\n",
    "    # identify all \"chunk\" nodes derived from a given article \n",
    "    prefix = f\"{article_id}_chunk\"\n",
    "    matching_nodes = [node for node in G.nodes if str(node).startswith(prefix)]\n",
    "\n",
    "    # for each chunk node \n",
    "    for node in matching_nodes:\n",
    "\n",
    "        # for each entity found in an article... \n",
    "        for entity in entities_dict[article_id]['entities']['entities']:\n",
    "\n",
    "            # Apply \"setdefault\" method with \"appears_in\" list of entity\n",
    "            entity.setdefault('appears_in', [])\n",
    "\n",
    "            # If the entity appears in the considered chunk...\n",
    "            if entity['name'] in G.nodes[node][\"text\"]:\n",
    "\n",
    "                # Add chunk node id to the entity's 'appears_in' list \n",
    "                entity['appears_in'].append(node)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#temperature = get_gpu_temeprature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/extracted_entities_B.pkl\", \"wb\") as f:\n",
    "    pickle.dump(entities_dict, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphsage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
