{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import yaml\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# ChromaDB imports\n",
    "import chromadb\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "try:\n",
    "    # This will work in scripts where __file__ is defined\n",
    "    current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    # Assuming \"src\" is parallel to the script folder\n",
    "    project_root = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "except NameError:\n",
    "    # In notebooks __file__ is not defined: assume we're in notebooks/\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))\n",
    "\n",
    "src_path = os.path.join(project_root, \"src\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "from main.node_embedding_models import GraphSAGE\n",
    "from main.ollama_utils import get_ollama_embedding\n",
    "from main.sage_utils import get_new_sage_embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bundle_name = \"bsard_2hop_20e_1024-768-512\"\n",
    "\n",
    "# Load Graph\n",
    "graph_path = os.path.join(\n",
    "    project_root, \"data\", \"retreival_bundles\", bundle_name, \"graph.pkl\"\n",
    "    )\n",
    "with open(graph_path, \"rb\") as f:\n",
    "    graph = pickle.load(f)\n",
    "\n",
    "# Load sage config\n",
    "config_file_path = os.path.join(\n",
    "    project_root, \"data\", \"retreival_bundles\", bundle_name, \"config.yaml\"\n",
    "    )\n",
    "with open(config_file_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "\n",
    "# Load SAGE model\n",
    "sage_model_path = os.path.join(\n",
    "    project_root, \"data\", \"retreival_bundles\", bundle_name, \"graphsage.pth\"\n",
    "    )\n",
    "\n",
    "# Define model and load weights\n",
    "model = GraphSAGE(\n",
    "    channels=config[\"model_params\"][\"channels\"],   \n",
    "    )\n",
    "try:\n",
    "    model.load_state_dict(torch.load(sage_model_path))\n",
    "except:\n",
    "    model.load_state_dict(torch.load(sage_model_path, map_location=torch.device('cpu')))\n",
    "model.eval() \n",
    "\n",
    "# Set device for model inference\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Move the model to the device\n",
    "model = model.to(device)\n",
    "\n",
    "# Load queries\n",
    "queries_path = os.path.join(\n",
    "    project_root, \"data\", \"BSARD_dataset\", \"bsard_train_questions.csv\"\n",
    "    )\n",
    "\n",
    "queries_df = pd.read_csv(queries_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [queries_df.head()['question'][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parallel_retrieval_pipeline(graph, queries, sage_model, semantic_embedder=get_ollama_embedding):\n",
    "\n",
    "    # Get queries semantic embedding\n",
    "    query_semantic_embeddings = []\n",
    "    for query in queries:\n",
    "        query_semantic_embeddings.append(semantic_embedder(query))\n",
    "    \n",
    "    # Get queries sage embedding\n",
    "    query_sage_embeddings = []\n",
    "    for query in query_semantic_embeddings:\n",
    "        query_sage_embeddings.append(get_new_sage_embedding(model=model, new_feature=torch.tensor(query, dtype=torch.float32).reshape(model.convs[0].in_channels), device=device))\n",
    "\n",
    "    # Create two chromadb collections\n",
    "    chroma_client = chromadb.Client()\n",
    "\n",
    "        # One for the semantic embeddings\n",
    "    collection_semantic = chroma_client.create_collection(name=\"semantic_collection\")\n",
    "        # Fill collection\n",
    "    for node_id in graph.nodes:\n",
    "        node_data = graph.nodes[node_id]\n",
    "        if node_data.get(\"node_type\") == \"Article\":\n",
    "            doc_text = node_data.get(\"article_text\", \"\")\n",
    "            doc_embedding = node_data.get(\"embedding\", None)\n",
    "        \n",
    "            # Ensure that doc_embedding is a list (or array) of floats\n",
    "            # Add the node to the collection by specifying IDs, documents, and embeddings\n",
    "            collection_semantic.add(\n",
    "                ids=[str(node_id)],         # The ID will be the node's ID (converted to a string)\n",
    "                documents=[doc_text],         # The node's text\n",
    "                embeddings=[doc_embedding]    # The precomputed embedding you already have\n",
    "                )\n",
    "            \n",
    "        # One for the sage embeddings\n",
    "    collection_sage = chroma_client.create_collection(name=\"sage_collection\")\n",
    "        # Fill collection\n",
    "    for node_id in graph.nodes:\n",
    "        node_data = graph.nodes[node_id]\n",
    "        if node_data.get(\"node_type\") == \"Article\":\n",
    "            doc_text = node_data.get(\"article_text\", \"\")\n",
    "            doc_embedding = node_data.get(\"hybrid_embedding\", None)\n",
    "        \n",
    "            # Ensure that doc_embedding is a list (or array) of floats\n",
    "            # Add the node to the collection by specifying IDs, documents, and embeddings\n",
    "            collection_sage.add(\n",
    "                ids=[str(node_id)],         # The ID will be the node's ID (converted to a string)\n",
    "                documents=[doc_text],         # The node's text\n",
    "                embeddings=[doc_embedding]    # The precomputed embedding you already have\n",
    "                )\n",
    "\n",
    "    # Retrieve top k documents from the semantic collection based on the query semantic embedding for each query (based on semantic embedding)\n",
    "    semantic_results = []\n",
    "    for query in query_semantic_embeddings:\n",
    "        topk_semantic    = collection_semantic.query(\n",
    "            query_embeddings=[query],\n",
    "            n_results=10\n",
    "        )\n",
    "        semantic_results.append(topk_semantic[\"ids\"])\n",
    "\n",
    "\n",
    "    # Retrieve top k documents from the sage collection based on the query sage embedding for each query (based on sage embedding)\n",
    "    sage_results = []\n",
    "    for query in query_sage_embeddings:\n",
    "        topk_sage    = collection_sage.query(\n",
    "            query_embeddings=[query],\n",
    "            n_results=10\n",
    "        )\n",
    "        sage_results.append(topk_sage[\"ids\"])\n",
    "\n",
    "    \n",
    "    return semantic_results, sage_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching embedding: HTTPConnectionPool(host='localhost', port=11434): Max retries exceeded with url: /api/embeddings (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x00000212AD871550>: Failed to establish a new connection: [WinError 10061] No se puede establecer una conexión ya que el equipo de destino denegó expresamente dicha conexión'))\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "must be real number, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mparallel_retrieval_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueries\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 11\u001b[39m, in \u001b[36mparallel_retrieval_pipeline\u001b[39m\u001b[34m(graph, queries, sage_model, semantic_embedder)\u001b[39m\n\u001b[32m      9\u001b[39m query_sage_embeddings = []\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m query \u001b[38;5;129;01min\u001b[39;00m query_semantic_embeddings:\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     query_sage_embeddings.append(get_new_sage_embedding(model=model, new_feature=\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m.reshape(model.convs[\u001b[32m0\u001b[39m].in_channels), device=device))\n\u001b[32m     13\u001b[39m \u001b[38;5;66;03m# Create two chromadb collections\u001b[39;00m\n\u001b[32m     14\u001b[39m chroma_client = chromadb.Client()\n",
      "\u001b[31mTypeError\u001b[39m: must be real number, not NoneType"
     ]
    }
   ],
   "source": [
    "parallel_retrieval_pipeline(graph, queries, model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311_graphsage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
