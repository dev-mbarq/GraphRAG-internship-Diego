{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "# Third party imports\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from azure.ai.inference import EmbeddingsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from pydantic import BaseModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ChromaDB imports\n",
    "import chromadb\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "\n",
    "try:\n",
    "    # This will work in scripts where __file__ is defined\n",
    "    current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    # Assuming \"src\" is parallel to the script folder\n",
    "    project_root = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "except NameError:\n",
    "    # In notebooks __file__ is not defined: assume we're in notebooks/riziv_dataset/\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "\n",
    "src_path = os.path.join(project_root, \"src\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "# Local application imports\n",
    "\n",
    "from riziv.riziv_article_code_format_utils import (\n",
    "    standardize_article_number,\n",
    "    std_to_sort_tuple,\n",
    ")\n",
    "from riziv.riziv_graph_building_utils import create_base_document_graph\n",
    "from riziv.riziv_graph_visualization_utils import (\n",
    "    visualize_node_1hop,\n",
    "    visualize_node_2hop,\n",
    ")\n",
    "\n",
    "from riziv.riziv_sequence_chunking_utils import (\n",
    "    split_text_with_overlap,\n",
    "    verify_overlap,\n",
    ")\n",
    "\n",
    "#from src.retrieval_utils import ( \n",
    "#    extract_date_from_query, \n",
    "#    get_query_embedding, \n",
    "#    get_valid_graph_at_date, \n",
    "#    create_chroma_collection_and_retrieve_top_k, \n",
    "#    filter_relevant_evidence,\n",
    "#    get_document_context,\n",
    "#    build_sources_citation,\n",
    "#    #get_article_title, \n",
    "#    #format_article_number,\n",
    "#    generate_final_answer\n",
    "#)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.graphsage import GraphSAGE\n",
    "import torch\n",
    "from scipy.spatial.distance import cosine\n",
    "import sys\n",
    "import pandas as pd\n",
    "import pickle\n",
    "sys.path.append('../')\n",
    "\n",
    "from src.retrieval_utils import ( \n",
    "    extract_date_from_query, \n",
    "    get_query_embedding, \n",
    "    get_valid_graph_at_date, \n",
    "    create_chroma_collection_and_retrieve_top_k, \n",
    "    filter_relevant_evidence,\n",
    "    get_document_context,\n",
    "    build_sources_citation,\n",
    "    get_article_title, \n",
    "    format_article_number,\n",
    "    generate_final_answer,\n",
    "    get_sage_embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"\"\"Je vous contacte par rapport à une pratique médicale qui me paraît douteuse. Ce soir, j’avais rdv chez XXX à Bruxelles pour une consultation avec un médecin en vue d’un possible traitement laser pour une cicatrise.\n",
    "La consultation ne dure que 2-3min et je demande au médecin s’il peut immédiatement commencer le traitement, ce qu’il me confirme.\n",
    "Après la séance laser, au moment de payer, la dame de l’accueil me demande 70€ pour le laser et 50€ pour la consultation avec le docteur. Je lui demande une feuille de soins pour la consultation avec le médecin, ce qu’elle refuse prétextant que les médecins esthétiques ne remettent pas de reçus aux patients.\n",
    "J’ai trouvé ça très curieux et j’ai insisté mais la personne à l’accueil s’est énervée. Finalement, le docteur ne l’a fait payer que la séance laser à 70€ (sans reçu donc) mais je me suis fait traiter comme une malpropre.\n",
    "Pouvez-vous me confirmer s’il est vrai qu’un médecin esthétique n’est pas tenu de remettre une attestation de soins pour une consultation?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "# Load graph w/embeddings and Article's data\n",
    "####################################\n",
    "\n",
    "print('-------------------------')\n",
    "print('Load data')\n",
    "\n",
    "with open('../data/document_graph_with_embeddings.pkl', 'rb') as f:\n",
    "    G_emb = pickle.load(f)\n",
    "\n",
    "#with open('graph_sage.pkl', 'rb') as f:\n",
    "#    G_emb = pickle.load(f)\n",
    "\n",
    "workArticlePlusLanguageFR = pd.read_csv('../data/df_workArticlePlusLanguageFR.csv')\n",
    "\n",
    "query_embedding = get_query_embedding(query)\n",
    "\n",
    "print('-------------------------')\n",
    "\n",
    "####################################\n",
    "# Extract relevant date from user query\n",
    "####################################\n",
    "\n",
    "print('-------------------------')\n",
    "print('Extract_date_from_query')\n",
    "\n",
    "relevant_date = extract_date_from_query(query)\n",
    "print(f\"Extracted date: {relevant_date}\")\n",
    "\n",
    "print('-------------------------')\n",
    "\n",
    "####################################\n",
    "# Prune graph\n",
    "####################################\n",
    "\n",
    "print('-------------------------')\n",
    "print('Get_valid_graph_at_date')\n",
    "\n",
    "G_at_date = get_valid_graph_at_date(G_emb, relevant_date)\n",
    "\n",
    "print('-------------------------')\n",
    "\n",
    "####################################\n",
    "# Instatiate chromdb and query vector database\n",
    "####################################\n",
    "\n",
    "print('-------------------------')\n",
    "print('Create_chroma_collection_and_retrieve_top_k')\n",
    "\n",
    "chroma_results = create_chroma_collection_and_retrieve_top_k(\n",
    "    G=G_at_date,  # Graph filtered by data\n",
    "    query_embedding=query_embedding,  # Query embedding\n",
    "    k=10  # Number of relevant docs to retrieve\n",
    ")\n",
    "\n",
    "chroma_results['ids']\n",
    "chroma_results_texts = chroma_results['documents'][0]\n",
    "\n",
    "print('-------------------------')\n",
    "\n",
    "####################################\n",
    "# Filter retrieved evidence\n",
    "####################################\n",
    "\n",
    "print('-------------------------')\n",
    "print('Filter_relevant_evidence')\n",
    "\n",
    "relevant_evidence = filter_relevant_evidence(\n",
    "        query=query,\n",
    "        evidence_texts=chroma_results_texts\n",
    "    )\n",
    "\n",
    "for i in relevant_evidence: \n",
    "    print(i[1] , \"\\n\")\n",
    "\n",
    "print('-------------------------')\n",
    "\n",
    "####################################\n",
    "# Get context of relevant evidence\n",
    "####################################\n",
    "\n",
    "print('-------------------------')\n",
    "print('Get_document_context')\n",
    "\n",
    "# Obtain ids of relevant text chunks\n",
    "relevant_chunk_ids = [chroma_results['ids'][0][idx] for idx, _ in relevant_evidence]\n",
    "\n",
    "# Get context\n",
    "context = get_document_context(G=G_at_date, chunk_ids=relevant_chunk_ids)\n",
    "\n",
    "# Opcional: Mostrar resultados\n",
    "for chunk_info in context:\n",
    "    print(f\"\\nChunk: {chunk_info['chunk_id']}\")\n",
    "    if chunk_info['article_info']:\n",
    "        print(f\"Article: {chunk_info['article_info']['sort_tuple']}\")\n",
    "    if chunk_info['act_info']:\n",
    "        print(f\"Act: {chunk_info['act_info']['title_short']}\")\n",
    "\n",
    "print('-------------------------')\n",
    "\n",
    "####################################\n",
    "# Build citation's block\n",
    "####################################\n",
    "\n",
    "print('-------------------------')\n",
    "print('Build_sources_citation')\n",
    "\n",
    "citation = build_sources_citation(context, workArticlePlusLanguageFR)\n",
    "print(citation)\n",
    "\n",
    "print('-------------------------')\n",
    "\n",
    "####################################\n",
    "# Produce final answer\n",
    "####################################\n",
    "\n",
    "print('-------------------------')\n",
    "print('Generate_final_answer')\n",
    "\n",
    "final_answer = generate_final_answer(query, relevant_evidence, context, workArticlePlusLanguageFR)\n",
    "print(final_answer + \"\\n\\n\\n\" + citation)\n",
    "\n",
    "print('-------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(chroma_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(relevant_evidence)\n",
    "print(len(relevant_evidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(context)\n",
    "print(len(relevant_evidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(relevant_evidence)):\n",
    "    piece_of_ev = relevant_evidence[i][1]\n",
    "    ev_article_n = get_article_title(format_article_number(context[i]['article_info']['article_number']), workArticlePlusLanguageFR)\n",
    "    ev_act_title = context[i]['act_info']['title_short']\n",
    "\n",
    "    \n",
    "    print(f\"Evidence {i}\", \"\\n\", ev_article_n, \" - \", ev_act_title, \"\\n\", piece_of_ev, \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(workArticlePlusLanguageFR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('-------------------------')\n",
    "print('Generate_final_answer')\n",
    "\n",
    "final_answer = generate_final_answer(query, relevant_evidence, context, workArticlePlusLanguageFR)\n",
    "print(final_answer + \"\\n\\n\\n\" + citation)\n",
    "\n",
    "print('-------------------------')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
