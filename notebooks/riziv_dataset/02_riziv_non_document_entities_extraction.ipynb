{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook details the extraction of additional relevant entities and relationships from the DOCLEG database to enrich the base document graph. The extraction is automated using LLMs and focuses on two main elements:\n",
    "\n",
    "- _Legal Concepts_: Identifying legally relevant concepts within the document texts. These concepts are added as new nodes in the graph, with edges linking them to the texts where they appear, thereby interconnecting different sub-graphs within the overall document graph.\n",
    "\n",
    "- _Document References_: Detecting references to other legal documents within the texts. These references are incorporated as new edges, connecting texts that mention other documents.\n",
    "\n",
    "The primary motivation for adding these entities is to enhance the graph’s ability to represent the comprehensive information contained in the DOCLEG database, ultimately facilitating more accurate and robust responses to user queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import sys\n",
    "\n",
    "# Third party imports\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from openai import AzureOpenAI\n",
    "from pydantic import BaseModel\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "# Determine the project root directory for relative imports\n",
    "try:\n",
    "    # This will work in scripts where __file__ is defined\n",
    "    current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "    # Assuming \"src\" is parallel to the script folder\n",
    "    project_root = os.path.abspath(os.path.join(current_dir, \"..\"))\n",
    "except NameError:\n",
    "    # In notebooks __file__ is not defined: assume we're in notebooks/riziv_dataset/\n",
    "    project_root = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "\n",
    "src_path = os.path.join(project_root, \"src\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "from riziv.riziv_structured_output_schemas import ConceptExtraction, CitationExtraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the path to the RIZIV dataset files\n",
    "RIZIV_data_path = os.path.join(project_root, \"data\", \"RIZIV_hackathon_main\")\n",
    "\n",
    "# Load the base document graph\n",
    "with open(os.path.join(RIZIV_data_path,'intermediate','base_document_graph.pkl'), 'rb') as f:\n",
    "    G = pickle.load(f)\n",
    "\n",
    "# Load the chunks DataFrame from CSV\n",
    "chunks_df = pd.read_csv(os.path.join(RIZIV_data_path,'intermediate', 'df_sequence_text_chunks.csv'))\n",
    "\n",
    "# Resolve .env path relative to this notebook\n",
    "env_path = os.path.join(RIZIV_data_path, '.env')\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "load_dotenv(dotenv_path=env_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Extraction of legal concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the extraction of relevant concepts an LLM was employed to sequentially analyze the texts within the based document graph and extract at most 10 relevant legal concepts from each one. Alongside the concepts themselves, the LLM is also instructed to return a category within a pre-defined list of categories for each relevant concept (see prompt template in code below) as well as a relevance score  to proxy the global relevance of each extracted concept within its text fragment as perceived by the LLM. The category is meant to be employed during the filtering and pre-processing of the relevant terms prior to their inclusion in the document graph as new nodes. Meanwhile, the relevance score is included in the output for similar reasons as well as an attempt to further steer the LLM's behaviour into including only concepts which appear to be globally relevant within a provided text fragment and minimize the appearence of \"noisy concepts\".\n",
    "\n",
    "Due to the time constrains faced during the hackathon, the extension of the DOCLEG database, and the potential computational and monetary costs associated with employing the presented approach at scale, extraction of legal concepts was only conducted over a sample of 3% of all text chunks within the base document graph. Applied at this level, the inclussion of these relevant legal concepts in the base document graph has a merely illustrative impact and is considered to have a negligible influence at the time of improving the quality of answers to the user's queries. The different constraints of the hackathon format prevented a further extension and refinement of this apporach which could lead to the realization of its proposed advantages.\n",
    "\n",
    "Following the flow of the code presented below, after the final dictionary of relevant legal concepts was extracted, it is converted into a DataFrame and stored to be used in subsequent notebooks to add these to the base document graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43436 chunks in total\n",
      "Processing 13 chunks (0.03% of total)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:   8%|▊         | 1/13 [00:06<01:14,  6.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 1:\n",
      "Tokens used: 833 (prompt) + 829 (completion) = 1662 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  15%|█▌        | 2/13 [00:24<02:24, 13.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 2:\n",
      "Tokens used: 1908 (prompt) + 2492 (completion) = 4400 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  23%|██▎       | 3/13 [00:44<02:43, 16.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 3:\n",
      "Tokens used: 1340 (prompt) + 2852 (completion) = 4192 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  31%|███       | 4/13 [00:57<02:16, 15.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 4:\n",
      "Tokens used: 884 (prompt) + 1631 (completion) = 2515 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  38%|███▊      | 5/13 [01:19<02:20, 17.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 5:\n",
      "Tokens used: 1369 (prompt) + 1810 (completion) = 3179 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  46%|████▌     | 6/13 [01:39<02:08, 18.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 6:\n",
      "Tokens used: 1049 (prompt) + 1527 (completion) = 2576 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  54%|█████▍    | 7/13 [01:51<01:38, 16.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 7:\n",
      "Tokens used: 974 (prompt) + 1651 (completion) = 2625 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  62%|██████▏   | 8/13 [02:08<01:21, 16.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 8:\n",
      "Tokens used: 844 (prompt) + 1360 (completion) = 2204 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  69%|██████▉   | 9/13 [02:28<01:10, 17.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 9:\n",
      "Tokens used: 833 (prompt) + 2059 (completion) = 2892 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  77%|███████▋  | 10/13 [02:47<00:54, 18.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 10:\n",
      "Tokens used: 1118 (prompt) + 2576 (completion) = 3694 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  85%|████████▍ | 11/13 [03:07<00:37, 18.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 11:\n",
      "Tokens used: 1708 (prompt) + 2760 (completion) = 4468 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  92%|█████████▏| 12/13 [03:30<00:20, 20.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 12:\n",
      "Tokens used: 1083 (prompt) + 1873 (completion) = 2956 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 100%|██████████| 13/13 [03:41<00:00, 17.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 13:\n",
      "Tokens used: 834 (prompt) + 1373 (completion) = 2207 total\n",
      "\n",
      "Final Statistics:\n",
      "Successfully processed 13 chunks\n",
      "Final results saved to chunk_concepts.pkl\n",
      "Found 56 unique concepts\n",
      "\n",
      "First few rows of the DataFrame:\n",
      "                                        concept_name  \\\n",
      "0  Contribution compensatoire pour firmes pharmac...   \n",
      "1                  Cotisation sur primes d'assurance   \n",
      "2               Formule de demande de renouvellement   \n",
      "3              Délai prescrit pour le renouvellement   \n",
      "4          Communication immédiate des modifications   \n",
      "\n",
      "              category_list relevance_list           chunk_list  \n",
      "0          [Financial Term]         [10.0]  [chunk_12044868_25]  \n",
      "1              [Obligation]          [9.0]  [chunk_12044868_25]  \n",
      "2  [Administrative Process]          [8.0]   [chunk_12004230_0]  \n",
      "3              [Obligation]          [7.0]   [chunk_12004230_0]  \n",
      "4              [Obligation]          [7.0]   [chunk_12004230_0]  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########################################################################################\n",
    "# Extraction of relevant legal concepts\n",
    "########################################################################################\n",
    "\n",
    "# Note (1): For testing purposes, the sample size was set to 0.03% of the total number of chunks in the \n",
    "# base document graph instead of the original 3% employed during the hackathon.\n",
    "\n",
    "# Note (2): All code segments related to tracking the costs of the API calls have been commented/disabled\n",
    "\n",
    "# Instantiate Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "# Dictionary to store all results\n",
    "all_concepts = {}\n",
    "\n",
    "# Note: All code segments related to tracking the costs of the API calls have been commented/disabled\n",
    "\n",
    "## Counters for tokens and cost\n",
    "#total_prompt_tokens = 0\n",
    "#total_completion_tokens = 0\n",
    "#total_cost = 0\n",
    "\n",
    "# Get list of chunk nodes from the graph\n",
    "chunk_nodes = [node for node in G.nodes() if G.nodes[node].get('type_node') == 'text_chunk']\n",
    "total_chunks = len(chunk_nodes)\n",
    "print(f\"Found {total_chunks} chunks in total\")\n",
    "\n",
    "# Calculate 0.03% sample size and get random sample\n",
    "sample_size = int(total_chunks * 0.0003)\n",
    "sampled_chunks = random.sample(chunk_nodes, sample_size)\n",
    "print(f\"Processing {sample_size} chunks ({0.03}% of total)\")\n",
    "\n",
    "# Iterate over sampled chunks with progress bar\n",
    "for idx, chunk_id in enumerate(tqdm(sampled_chunks, desc=\"Processing chunks\")):\n",
    "    # Get text from chunk\n",
    "    chunk_text = G.nodes[chunk_id]['text']\n",
    "    \n",
    "    try:\n",
    "        # Call API for concept extraction\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"), \n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"\"\"You are an expert legal analyst specialized in Belgian legal texts from the RIZIV/INAMI corpus. \n",
    "                 Your task is to extract only the most relevant legal concepts from legal text fragments in French, focusing on abstract legal ideas, \n",
    "                 doctrines, and specialized terminology that are specific to the healthcare and social security domain covered by RIZIV/INAMI. \n",
    "                 You may encounter text fragments of varying length make sure to extract only the most relevant concepts\n",
    "                 within the global context of the presented text. Also, assign each extracted concept one category from the following list: \n",
    "                 [Obligation, Legal Principle, Regulation, Financial Term, Administrative Process, Institution, Key Terminology, Other].\n",
    "                 Do not include citations, dates, locations, or extraneous details. \n",
    "\n",
    "                Your output must strictly follow the JSON schema below, contain no additional commentary, and be limited to a maximum of 10 concepts, \n",
    "                 ordered from highest to lowest relevance. If no relevant legal concepts are identified, return an empty \"concepts\" list.\"\"\"},\n",
    "\n",
    "                {\"role\": \"user\", \"content\": f\"\"\"Extract the key legal concepts from the following French legal text fragment, \n",
    "                 which comes from the RIZIV/INAMI corpus. Only include legal concepts that are highly relevant and specific to healthcare \n",
    "                 legislation and social security in Belgium. Limit your output to a maximum of 10 concepts, ordered by relevance, \n",
    "                 and if there are no relevant legal concepts, return an empty \"concepts\" list.\n",
    "                 Text: {chunk_text}\"\"\"},\n",
    "            ],\n",
    "            response_format=ConceptExtraction,\n",
    "        )\n",
    "        \n",
    "        # Update token counters and calculate costs\n",
    "        prompt_tokens = completion.usage.prompt_tokens\n",
    "        completion_tokens = completion.usage.completion_tokens\n",
    "        \n",
    "        #total_prompt_tokens += prompt_tokens\n",
    "        #total_completion_tokens += completion_tokens\n",
    "        \n",
    "        ## Calculate costs in euros\n",
    "        #prompt_cost = (prompt_tokens * 1.047) / 1000000\n",
    "        #completion_cost = (completion_tokens * 4.19) / 1000000\n",
    "        #total_cost += prompt_cost + completion_cost\n",
    "        \n",
    "        # Process API response and create concept dictionary\n",
    "        concepts = completion.choices[0].message.parsed\n",
    "        concept_dict = {}\n",
    "        \n",
    "        for i in range(1, 11):\n",
    "            concept_dict[i] = {\n",
    "                \"concept_name\": getattr(concepts, f\"concept{i}_name\"),\n",
    "                \"category\": getattr(concepts, f\"concept{i}_category\"),\n",
    "                \"relevance\": getattr(concepts, f\"concept{i}_relevance\")\n",
    "            }\n",
    "        \n",
    "        # Store in global dictionary\n",
    "        all_concepts[chunk_id] = concept_dict\n",
    "        \n",
    "        # Print token usage and cost for this iteration\n",
    "        print(f\"\\nIteration {idx + 1}:\")\n",
    "        print(f\"Tokens used: {prompt_tokens} (prompt) + {completion_tokens} (completion) = {prompt_tokens + completion_tokens} total\")\n",
    "        #print(f\"Accumulated cost: {total_cost:.6f} EUR\")\n",
    "        \n",
    "        # Save intermediate results every 100 iterations\n",
    "        if (idx + 1) % 100 == 0:\n",
    "            with open(os.path.join(RIZIV_data_path, 'chunk_concepts_checkpoint.pkl'), 'wb') as f:\n",
    "                pickle.dump(all_concepts, f)\n",
    "            print(f\"Checkpoint saved at {idx + 1} chunks\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing chunk {chunk_id}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nFinal Statistics:\")\n",
    "print(f\"Successfully processed {len(all_concepts)} chunks\")\n",
    "#print(f\"Total tokens used: {total_prompt_tokens} (prompt) + {total_completion_tokens} (completion) = {total_prompt_tokens + total_completion_tokens} total\")\n",
    "#print(f\"Total cost: {total_cost:.6f} EUR\")\n",
    "\n",
    "# Save final results' dictionary to pickle file\n",
    "with open(os.path.join(RIZIV_data_path,'intermediate','chunk_concepts.pkl'), 'wb') as f:\n",
    "    pickle.dump(all_concepts, f)\n",
    "print(\"Final results saved to chunk_concepts.pkl\")\n",
    "\n",
    "########################################################################################\n",
    "# Converting the dictionary of concepts into a DataFrame\n",
    "########################################################################################    \n",
    "\n",
    "# Dictionary to store the concepts information\n",
    "concept_info = defaultdict(lambda: {'categories': set(), 'relevances': set(), 'chunks': set()})\n",
    "\n",
    "# Iterate through all chunks and their concepts\n",
    "for chunk_id, concepts in all_concepts.items():\n",
    "    for concept_dict in concepts.values():\n",
    "        # Skip empty concepts (where concept_name is empty)\n",
    "        if not concept_dict['concept_name']:\n",
    "            continue\n",
    "            \n",
    "        concept_name = concept_dict['concept_name']\n",
    "        concept_info[concept_name]['categories'].add(concept_dict['category'])\n",
    "        concept_info[concept_name]['relevances'].add(concept_dict['relevance'])\n",
    "        concept_info[concept_name]['chunks'].add(chunk_id)\n",
    "\n",
    "# Convert to DataFrame format\n",
    "df_data = []\n",
    "for concept, info in concept_info.items():\n",
    "    df_data.append({\n",
    "        'concept_name': concept,\n",
    "        'category_list': sorted(list(info['categories'])),\n",
    "        'relevance_list': sorted(list(info['relevances']), reverse=True),\n",
    "        'chunk_list': sorted(list(info['chunks']))\n",
    "    })\n",
    "\n",
    "# Create DataFrame\n",
    "concepts_df = pd.DataFrame(df_data)\n",
    "\n",
    "# Sort by frequency (length of chunk_list)\n",
    "concepts_df['freq'] = concepts_df['chunk_list'].str.len()\n",
    "concepts_df = concepts_df.sort_values('freq', ascending=False)\n",
    "concepts_df = concepts_df.drop('freq', axis=1)\n",
    "\n",
    "# Reset index for clean display\n",
    "concepts_df = concepts_df.reset_index(drop=True)\n",
    "\n",
    "print(f\"Found {len(concepts_df)} unique concepts\")\n",
    "print(\"\\nFirst few rows of the DataFrame:\")\n",
    "print(concepts_df.head())\n",
    "\n",
    "# Save concepts DataFrame to pickle file\n",
    "concepts_df.to_pickle(os.path.join(RIZIV_data_path,'intermediate', 'df_concepts.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Basic exploration of the dataframe of relevant concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptive statistics of mentions per concept:\n",
      "------------------------------------------------\n",
      "Minimum: 1\n",
      "Maximum: 1\n",
      "Mean: 1.00\n",
      "Median: 1.0\n",
      "Standard deviation: 0.00\n",
      "\n",
      "Percentiles:\n",
      "25%: 1.0\n",
      "50%: 1.0\n",
      "75%: 1.0\n",
      "90%: 1.0\n",
      "95%: 1.0\n",
      "99%: 1.0\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 most mentioned concepts:\n",
      "--------------------------------\n",
      "                                         concept_name  n_mentions\n",
      "0   Contribution compensatoire pour firmes pharmac...           1\n",
      "1                   Cotisation sur primes d'assurance           1\n",
      "2                Formule de demande de renouvellement           1\n",
      "3               Délai prescrit pour le renouvellement           1\n",
      "4           Communication immédiate des modifications           1\n",
      "5    Institut national d'assurance maladie-invalidité           1\n",
      "6                   Budget des frais d'administration           1\n",
      "7                                          Abrogation           1\n",
      "8                                              Arrêté           1\n",
      "9       Agrément spécial maisons de repos et de soins           1\n",
      "10                   Heures de formation obligatoires           1\n",
      "11          Formule de calcul des heures de formation           1\n",
      "12             Critères de conformité de l'article 22           1\n",
      "13  Période de facturation et de référence pour l'...           1\n",
      "14                             Nouvelles institutions           1\n",
      "15                 Classification des patients B et C           1\n",
      "16        Commission de remboursement des médicaments           1\n",
      "17                               Révision par groupes           1\n",
      "18                              Base de remboursement           1\n",
      "19                         Catégorie de remboursement           1\n"
     ]
    }
   ],
   "source": [
    "# Create a series with chunk_list lengths\n",
    "lengths = concepts_df['chunk_list'].str.len()\n",
    "\n",
    "# Get descriptive statistics\n",
    "print(\"Descriptive statistics of mentions per concept:\")\n",
    "print(\"------------------------------------------------\")\n",
    "print(f\"Minimum: {lengths.min()}\")\n",
    "print(f\"Maximum: {lengths.max()}\")\n",
    "print(f\"Mean: {lengths.mean():.2f}\")\n",
    "print(f\"Median: {lengths.median()}\")\n",
    "print(f\"Standard deviation: {lengths.std():.2f}\")\n",
    "print(\"\\nPercentiles:\")\n",
    "print(f\"25%: {lengths.quantile(0.25)}\")\n",
    "print(f\"50%: {lengths.quantile(0.50)}\")\n",
    "print(f\"75%: {lengths.quantile(0.75)}\")\n",
    "print(f\"90%: {lengths.quantile(0.90)}\")\n",
    "print(f\"95%: {lengths.quantile(0.95)}\")\n",
    "print(f\"99%: {lengths.quantile(0.99)}\")\n",
    "\n",
    "# Frequency histogram\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(lengths, bins=50, edgecolor='black')\n",
    "plt.title('Distribution of mentions per concept')\n",
    "plt.xlabel('Number of mentions')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Top 10 most mentioned concepts\n",
    "print(\"\\nTop 10 most mentioned concepts:\")\n",
    "print(\"--------------------------------\")\n",
    "top_20 = concepts_df.head(20)[['concept_name', 'chunk_list']].copy()\n",
    "top_20['n_mentions'] = top_20['chunk_list'].str.len()\n",
    "print(top_20[['concept_name', 'n_mentions']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Extraction of citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The proposed approach for extracting references to other legal documents within the texts of the DOCLEG database follows the same logic as the one used for detecting relevant legal concepts, that is, sequentially prompting an LLM over text fragments to identify and return such references.\n",
    "\n",
    "However, despite having the code ready to carry out this task, the time constraints imposed by the hackathon led to the decision to discard the inclusion of citation edges in the graph used for the Q&A retrieval prototype. Additionally, adding these citation edges was considered to require a higher level of attention during pre-processing, in order to detect potential artifacts in the extracted citations or to avoid introducing inaccurate edges into the graph. Without careful handling, which is a time-consuming process in itself, including these edges was evaluated as unfeasible within the timeframe of the hackathon, even for illustrative purposes, and even less so for having any meaningful impact on the quality of answers to user queries.\n",
    "\n",
    "Below, a series of functional code blocks are presented for the extraction of citations from DOCLEG texts. As previously mentioned, however, these were not used for building the graph employed in the final prototype presented at the end of the hackathon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text:\n",
      "Art. 46.\n",
      "Pour l'année [:W]2015[:w], il est instauré une contribution compensatoire à charge des distributeurs visés à l'[:C 1]article 33, § 1er, alinéa 1er, 3°[:c].\n",
      "Le montant de cette contribution s'élève à [:W]0,13 p.c.[:w] du chiffre d'affaires, tel que pris en compte pour l'application de l'[:C 1]article 34[:c], qui a été réalisé en [:W]2015[:w] et est versé par le biais d'un acompte, fixé à [:W]0,13 p.c.[:w] du chiffre d'affaires réalisé en [:w]2014[:w], et d'un solde. Ce solde est la différence entre la contribution même et l'acompte payé.\n",
      "La contribution visée à l'alinéa 1er est perçue par l'AFMPS pour le compte de l'Institut national d'assurance maladie-invalidité.\n",
      "Les articles [:C 1]36[:c] à [:C 2]41[:c] s'appliquent pour l'établissement et le recouvrement de la contribution compensatoire prévu à l'alinéa premier.\n",
      "\n",
      "Extracting citations...\n",
      "\n",
      "Extracted citations:\n",
      "\n",
      "Tokens used: 612 (prompt) + 727 (completion) = 1339 total\n"
     ]
    }
   ],
   "source": [
    "########################################################################################\n",
    "# Testing citations extration\n",
    "########################################################################################\n",
    "\n",
    "# Set up the Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "# Random text testing example for citations extraction (A single random text chunk)\n",
    "sample_text = chunks_df.sample(1)['text'].values[0]\n",
    "print(\"Sample text:\")\n",
    "print(sample_text)\n",
    "print(\"\\nExtracting citations...\")\n",
    "\n",
    "completion = client.beta.chat.completions.parse(\n",
    "    model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"), \n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"\"\"You are an expert legal analyst specialized in Belgian legal texts. \n",
    "         Your task is to extract only the legal citations that reference other laws, or legal texts, \n",
    "        from a given legal text fragment in French. Focus solely on these citations—do not include dates, \n",
    "         locations, or any other commentary. These citations should reference legal texts other than the\n",
    "         ones from which the provided fragments were originally extracted. To make sure this is the case do not\n",
    "         extract references to articles unless it is explicit and clear in the text that they belong to a different piece\n",
    "         of legislation/act.\n",
    "\n",
    "        Assign each extracted citation exactly one field \"citation\". You must limit your output to a maximum of 2 citations, \n",
    "         ordered by their relevance if applicable. If no legal citations are identified, return an empty \"citations\" list.\"\"\"},\n",
    "\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"Extract the legal citations from the following French legal text fragment. \n",
    "         Only include citations that reference other laws or legal texts (i.e., legal references that do not belong to the source document). \n",
    "         If a reference to an article appears, include it only if it is explicitly clear that it belongs to a different piece of legislation \n",
    "         or act. Return your output strictly following the JSON schema provided, with a maximum of 2 citations ordered by relevance. \n",
    "         If no legal citations are identified, return an empty \"citations\" list.\n",
    "\n",
    "         Text: {sample_text}\"\"\"},\n",
    "    ],\n",
    "    response_format=CitationExtraction,\n",
    ")\n",
    "\n",
    "# Access result as Python object\n",
    "citations = completion.choices[0].message.parsed\n",
    "\n",
    "print(\"\\nExtracted citations:\")\n",
    "for i in range(1, 3):  # Maximum of 2 citations\n",
    "    citation = getattr(citations, f\"citation{i}\", None)\n",
    "    if citation:\n",
    "        print(f\"Citation {i}: {citation}\")\n",
    "\n",
    "# Print token usage\n",
    "print(f\"\\nTokens used: {completion.usage.prompt_tokens} (prompt) + {completion.usage.completion_tokens} (completion) = {completion.usage.total_tokens} total\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 43436 chunks in total\n",
      "Processing 13 chunks (0.03% of total)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks:  77%|███████▋  | 10/13 [01:36<00:32, 10.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Iteration 10:\n",
      "Tokens used: 1270 (prompt) + 838 (completion) = 2108 total\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing chunks: 100%|██████████| 13/13 [01:56<00:00,  8.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Statistics:\n",
      "Successfully processed 8 chunks with citations\n",
      "Total tokens used: 8976 (prompt) + 13719 (completion) = 22695 total\n",
      "Final results saved to chunk_citations.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "########################################################################################\n",
    "# Serial citations extraction\n",
    "########################################################################################\n",
    "\n",
    "# Set up the Azure OpenAI client\n",
    "client = AzureOpenAI(\n",
    "    api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "    azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "    api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "# Define dictionary to store all citations\n",
    "all_citations = {}\n",
    "\n",
    "# Counters for tokens and cost\n",
    "total_prompt_tokens = 0\n",
    "total_completion_tokens = 0\n",
    "total_cost = 0\n",
    "\n",
    "# Get list of chunk nodes from the graph\n",
    "chunk_nodes = [node for node in G.nodes() if G.nodes[node].get('type_node') == 'text_chunk']\n",
    "total_chunks = len(chunk_nodes)\n",
    "\n",
    "# Calculate 0.03% sample size and get random sample\n",
    "sample_size = int(total_chunks * 0.0003)\n",
    "sampled_chunks = random.sample(chunk_nodes, sample_size)\n",
    "print(f\"Found {total_chunks} chunks in total\")\n",
    "print(f\"Processing {sample_size} chunks ({0.03}% of total)\")\n",
    "\n",
    "# Iterate over sampled chunks with progress bar\n",
    "for idx, chunk_id in enumerate(tqdm(sampled_chunks, desc=\"Processing chunks\")):\n",
    "    # Get text from chunk\n",
    "    chunk_text = G.nodes[chunk_id]['text']\n",
    "    \n",
    "    try:\n",
    "        # Call API for citation extraction\n",
    "        completion = client.beta.chat.completions.parse(\n",
    "            model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"), \n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"\"\"You are an expert legal analyst specialized in Belgian legal texts. \n",
    "                 Your task is to extract only the legal citations that reference other laws, or legal texts, \n",
    "                from a given legal text fragment in French. Focus solely on these citations—do not include dates, \n",
    "                 locations, or any other commentary. These citations should reference legal texts other than the\n",
    "                 ones from which the provided fragments were originally extracted. To make sure this is the case do not\n",
    "                 extract references to articles unless it is explicit and clear in the text that they belong to a different piece\n",
    "                 of legislation/act.\n",
    "\n",
    "                Assign each extracted citation exactly one field \"citation\". You must limit your output to a maximum of 2 citations, \n",
    "                 ordered by their relevance if applicable. If no legal citations are identified, return an empty \"citations\" list.\"\"\"},\n",
    "\n",
    "                {\"role\": \"user\", \"content\": f\"\"\"Extract the legal citations from the following French legal text fragment. \n",
    "                 Only include citations that reference other laws or legal texts (i.e., legal references that do not belong to the source document). \n",
    "                 If a reference to an article appears, include it only if it is explicitly clear that it belongs to a different piece of legislation \n",
    "                 or act. Return your output strictly following the JSON schema provided, with a maximum of 2 citations ordered by relevance. \n",
    "                 If no legal citations are identified, return an empty \"citations\" list.\n",
    "\n",
    "                 Text: {chunk_text}\"\"\"},\n",
    "            ],\n",
    "            response_format=CitationExtraction,\n",
    "        )\n",
    "        \n",
    "        # Update token counters and calculate costs\n",
    "        prompt_tokens = completion.usage.prompt_tokens\n",
    "        completion_tokens = completion.usage.completion_tokens\n",
    "        \n",
    "        total_prompt_tokens += prompt_tokens\n",
    "        total_completion_tokens += completion_tokens\n",
    "        \n",
    "        # Calculate costs in euros\n",
    "        #prompt_cost = (prompt_tokens * 1.047) / 1000000\n",
    "        #completion_cost = (completion_tokens * 4.19) / 1000000\n",
    "        #total_cost += prompt_cost + completion_cost\n",
    "        \n",
    "        # Process API response and create citations dictionary\n",
    "        citations = completion.choices[0].message.parsed\n",
    "        citations_dict = {}\n",
    "        \n",
    "        for i in range(1, 3):  # Maximum of 2 citations\n",
    "            citation = getattr(citations, f\"citation{i}\", None)\n",
    "            if citation:\n",
    "                citations_dict[i] = citation\n",
    "        \n",
    "        # Store in global dictionary only if citations were found\n",
    "        if citations_dict:\n",
    "            all_citations[chunk_id] = citations_dict\n",
    "        \n",
    "        # Print token usage and cost for this iteration\n",
    "        if (idx + 1) % 10 == 0:  # Print every 10 iterations to reduce output\n",
    "            print(f\"\\nIteration {idx + 1}:\")\n",
    "            print(f\"Tokens used: {prompt_tokens} (prompt) + {completion_tokens} (completion) = {prompt_tokens + completion_tokens} total\")\n",
    "            #print(f\"Accumulated cost: {total_cost:.6f} EUR\")\n",
    "        \n",
    "        # Save intermediate results every 100 iterations\n",
    "        if (idx + 1) % 100 == 0:\n",
    "            with open('chunk_citations_checkpoint.pkl', 'wb') as f:\n",
    "                pickle.dump(all_citations, f)\n",
    "            print(f\"Checkpoint saved at {idx + 1} chunks\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing chunk {chunk_id}: {str(e)}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\nFinal Statistics:\")\n",
    "print(f\"Successfully processed {len(all_citations)} chunks with citations\")\n",
    "print(f\"Total tokens used: {total_prompt_tokens} (prompt) + {total_completion_tokens} (completion) = {total_prompt_tokens + total_completion_tokens} total\")\n",
    "#print(f\"Total cost: {total_cost:.6f} EUR\")\n",
    "\n",
    "# Save final results to pickle file\n",
    "with open(os.path.join(RIZIV_data_path,'intermediate', 'chunk_citations.pkl'), 'wb') as f:\n",
    "    pickle.dump(all_citations, f)\n",
    "print(\"Final results saved to chunk_citations.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311_graphsage",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
